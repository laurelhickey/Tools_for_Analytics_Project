{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25627e8d",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project._\n",
    "\n",
    "* Code clarity: make sure the code conforms to:\n",
    "    * [ ] [PEP 8](https://peps.python.org/pep-0008/) - You might find [this resource](https://realpython.com/python-pep8/) helpful as well as [this](https://github.com/dnanhkhoa/nb_black) or [this](https://jupyterlab-code-formatter.readthedocs.io/en/latest/) tool\n",
    "    * [ ] [PEP 257](https://peps.python.org/pep-0257/)\n",
    "    * [ ] Break each task down into logical functions\n",
    "* The following files are submitted for the project (see the project's GDoc for more details):\n",
    "    * [ ] `README.md`\n",
    "    * [ ] `requirements.txt`\n",
    "    * [ ] `.gitignore`\n",
    "    * [ ] `schema.sql`\n",
    "    * [ ] 6 query files (using the `.sql` extension), appropriately named for the purpose of the query\n",
    "    * [x] Jupyter Notebook containing the project (this file!)\n",
    "* [x] You can edit this cell and add a `x` inside the `[ ]` like this task to denote a completed task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "# !pip install matplotlib\n",
    "# !pip install requests\n",
    "# !pip install bs4\n",
    "# !pip install sqlalchemy\n",
    "# !pip install pandas\n",
    "# !pip install geojsonio --upgrade\n",
    "# !pip install geopandas\n",
    "import math\n",
    "from math import *\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import re\n",
    "import datetime\n",
    "import geojsonio\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b622a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any general notebook setup, like log formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need, for example:\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "# add other constants to refer to any local data, e.g. uber & weather\n",
    "UBER_CSV = \"uber_rides_sample.csv\"\n",
    "# weather csv data file\n",
    "# 2009_weather to 2015_weather (just pick the first 6 months)\n",
    "csv__= '/Users/morax/Documents/哥大/IEORE4501/IEOR4501 HW/IEOR4501 Project/'\n",
    "csv09_file = csv__ + '2009_weather.csv'\n",
    "csv10_file = csv__ + '2010_weather.csv'\n",
    "csv11_file = csv__ + '2011_weather.csv'\n",
    "csv12_file = csv__ + '2012_weather.csv'\n",
    "csv13_file = csv__ + '2013_weather.csv'\n",
    "csv14_file = csv__ + '2014_weather.csv'\n",
    "csv15_file = csv__ + '2015_weather.csv'\n",
    "\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculating distance\n",
    "In this section in order to calculate the distance between two points in the uber data, we must use the longitude and latitude of the pickup and drop off locations.  Therefore, by using math module in order to calculate the distance between these two coordinates is given in the function calculate_distance().  It is important to note that, there are more accurate ways to calculate the distance based upon longitude and latitude that do not use just the math module.  In addtion, in the taxi data sets, the distance is already calculated, however, it is given in miles, so the miles_to_km() function converts the miles to kilometers so that a direct comparison between taxis and ubers can be made.  It should also be noted that the taxi distance is a distance driving on city streets whereas the uber distance is just a birdseye view distance, therefore, the distances in the taxi data set are likely to be slightly longer.  The function, add_distance_column() can be used in order to add the calculated distance to the uber data set.  This function uses the pickup and drop off longitudes and latitudes in order to build the additional column row by row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(from_coord, to_coord):\n",
    "    # Longitude is x, Latitude is y, \n",
    "    # Longitude x\n",
    "    long = (to_coord[0]-from_coord[0])*40000*math.cos((to_coord[1]+from_coord[1])*math.pi/360)/360\n",
    "    # Latitude y\n",
    "    lat = (to_coord[1]-from_coord[1])*40000/360\n",
    "    # so the distance is just the side z followed by x^2+y^2=z^2\n",
    "    distance = sqrt(long*long+lat*lat)\n",
    "    return distance\n",
    "\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "def calculate_distance2(from_coord, to_coord):\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "\n",
    "    # Longitude is x, Latitude is y, \n",
    "    # math.radians() converts a degree value into radians. \n",
    "    lon1 = radians(from_coord[0])\n",
    "    lat1 = radians(from_coord[1])\n",
    "    lon2 = radians(to_coord[0])\n",
    "    lat2 = radians(to_coord[1])\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "\n",
    "    return distance\n",
    "\n",
    "# well sometime calculate_distance is better than calculate_distance2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc07e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miles_to_km(distance_miles):\n",
    "    distance_km = distance_miles /0.62137119\n",
    "    return distance_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6d6abf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to fix the variable names called in lambda function\n",
    "def add_distance_column(dataframe): \n",
    "    dataframe['distance'] = dataframe.apply(lambda x: calculate_distance((x['pickup_longitude'], x[\"pickup_latitude\"]), (x['dropoff_longitude'], x['dropoff_latitude'])),axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Processing Taxi Data\n",
    "\n",
    "In this section, the taxi data set is being processed, the first step in processing the taxi data is first finding the links, then once those links are found they must be read in, and processed by combining each dataset for each month and year into one larger dataset and changing the distance column from miles to kilometers.\n",
    "\n",
    "-**get_taxi_html() and find_taxi_parquet_urls():** These functions are implementing web scraping in order to find the links for each data set of yellow taxi cabs. The first function, get_taxi_html(), is returning the html content of the web page that has the Taxi data. The second function, find_taxi_parquet_links is from the web page pulling out all of the links, then iterating through those links to see which are datasets for yellow taxi cabs from January 2009 to June 2015.\n",
    "\n",
    "-**get_and_clean_month_taxi_data(url)** This function reads in the data for each month of each year.  In addition, this funciton also takes a sample of the dataset to match the size of the Uber's dataset.  This means that as the Uber dataset has 1.8 million data points if it is assumed that those data points are evenly distributed across the 78 months, each of the taxi datasets should have approximatly 23076.9 rows in it, therefore, each parquet file is randomly sampled to pick out 23080 rows.\n",
    "\n",
    "-**zones_within_bbox()** This is a function that uses the taxi zone json file and using the centriod of the zone determines if that zone is within the bounding box (http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047).  If the zone is within the box it is included in the output list which is used later to remove data from some of the taxi files that do not have latitude and longitude included in their data.\n",
    "\n",
    "-**get_and_clean_taxi_data()** This function concatinates all of the data for each month of each year into one large data set. In addition, it cleans the dataframe data types, removes any points that are outside of the bounding box (http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047) that is essentially the bounds of NYC and normalizes the column names in the files that are from 2009 to 2010 and 2011 to 2015 as they have slightly different names and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_taxi_html():\n",
    "    response = requests.get(TAXI_URL)\n",
    "    html = response.content\n",
    "    # check if the request was succeeded\n",
    "    if not response.status_code == 200:\n",
    "        return None\n",
    "    return html\n",
    "\n",
    "\n",
    "def find_taxi_parquet_urls():\n",
    "    soup = bs4.BeautifulSoup(get_taxi_html(), 'html.parser')\n",
    "    yellow_pattern = r\"yellow_tripdata\"\n",
    "    # from Jan. 2009 to June 2015\n",
    "    year_pattern = r\"200\\d{1}\" # from Jan. 2009 to Dec. 2009\n",
    "    year_pattern2 = r\"201[01234]\" # from Jan. 2010 to Dec.2014\n",
    "    pattern2015 = r\"2015-0[123456]\" # from Jan. 2015 to June 2015\n",
    "    link_list = [a['href'] for a in soup.find_all('a')[30:-25]]\n",
    "    new_links = list()\n",
    "    for item in link_list:\n",
    "        # iterate through each year 2009 - 2015\n",
    "        if (re.search(yellow_pattern, item) != None): \n",
    "            if (re.search(year_pattern, item) != None):\n",
    "                new_links.append(item)\n",
    "            if (re.search(year_pattern2, item) != None):\n",
    "                new_links.append(item)\n",
    "            if (re.search(pattern2015, item) != None):\n",
    "                new_links.append(item)\n",
    "    return new_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_month_taxi_data(url):\n",
    "    dataframe = pd.read_parquet(url,engine='pyarrow')\n",
    "    # Taking a sample of the taxi data:\n",
    "    return dataframe.sample(n = 23080, random_state=39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be57e277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10566313</th>\n",
       "      <td>2015-01-26 00:57:34</td>\n",
       "      <td>2015-01-26 01:06:47</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>164</td>\n",
       "      <td>79</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100166</th>\n",
       "      <td>2015-01-17 21:43:25</td>\n",
       "      <td>2015-01-17 21:47:11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>234</td>\n",
       "      <td>90</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332144</th>\n",
       "      <td>2015-01-01 20:37:28</td>\n",
       "      <td>2015-01-01 20:48:13</td>\n",
       "      <td>3</td>\n",
       "      <td>1.34</td>\n",
       "      <td>142</td>\n",
       "      <td>161</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841470</th>\n",
       "      <td>2015-01-03 10:43:15</td>\n",
       "      <td>2015-01-03 10:50:28</td>\n",
       "      <td>1</td>\n",
       "      <td>2.82</td>\n",
       "      <td>229</td>\n",
       "      <td>148</td>\n",
       "      <td>9.5</td>\n",
       "      <td>11.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6119963</th>\n",
       "      <td>2015-01-15 20:31:59</td>\n",
       "      <td>2015-01-15 20:36:17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>249</td>\n",
       "      <td>114</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8807639</th>\n",
       "      <td>2015-01-22 06:50:02</td>\n",
       "      <td>2015-01-22 06:55:14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.20</td>\n",
       "      <td>239</td>\n",
       "      <td>142</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193240</th>\n",
       "      <td>2015-01-09 09:03:50</td>\n",
       "      <td>2015-01-09 09:20:19</td>\n",
       "      <td>1</td>\n",
       "      <td>1.70</td>\n",
       "      <td>24</td>\n",
       "      <td>143</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12323399</th>\n",
       "      <td>2015-01-31 07:50:47</td>\n",
       "      <td>2015-01-31 07:54:26</td>\n",
       "      <td>1</td>\n",
       "      <td>0.48</td>\n",
       "      <td>164</td>\n",
       "      <td>170</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697863</th>\n",
       "      <td>2015-01-12 16:42:51</td>\n",
       "      <td>2015-01-12 17:21:29</td>\n",
       "      <td>1</td>\n",
       "      <td>5.90</td>\n",
       "      <td>186</td>\n",
       "      <td>7</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030186</th>\n",
       "      <td>2015-01-28 10:37:55</td>\n",
       "      <td>2015-01-28 10:46:09</td>\n",
       "      <td>1</td>\n",
       "      <td>1.05</td>\n",
       "      <td>237</td>\n",
       "      <td>162</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "10566313  2015-01-26 00:57:34   2015-01-26 01:06:47                1   \n",
       "7100166   2015-01-17 21:43:25   2015-01-17 21:47:11                1   \n",
       "332144    2015-01-01 20:37:28   2015-01-01 20:48:13                3   \n",
       "841470    2015-01-03 10:43:15   2015-01-03 10:50:28                1   \n",
       "6119963   2015-01-15 20:31:59   2015-01-15 20:36:17                1   \n",
       "8807639   2015-01-22 06:50:02   2015-01-22 06:55:14                1   \n",
       "3193240   2015-01-09 09:03:50   2015-01-09 09:20:19                1   \n",
       "12323399  2015-01-31 07:50:47   2015-01-31 07:54:26                1   \n",
       "4697863   2015-01-12 16:42:51   2015-01-12 17:21:29                1   \n",
       "11030186  2015-01-28 10:37:55   2015-01-28 10:46:09                1   \n",
       "\n",
       "          trip_distance  PULocationID  DOLocationID  fare_amount  total_amount  \n",
       "10566313           2.40           164            79         10.0         12.80  \n",
       "7100166            0.80           234            90          4.5          7.25  \n",
       "332144             1.34           142           161          8.5          9.80  \n",
       "841470             2.82           229           148          9.5         11.90  \n",
       "6119963            0.81           249           114          5.0          7.68  \n",
       "8807639            1.20           239           142          6.5          7.30  \n",
       "3193240            1.70            24           143         11.5         12.30  \n",
       "12323399           0.48           164           170          4.5          6.30  \n",
       "4697863            5.90           186             7         25.0         26.80  \n",
       "11030186           1.05           237           162          7.0          7.80  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(find_taxi_parquet_urls())\n",
    "test_parquet= get_and_clean_month_taxi_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-01.parquet')\n",
    "test_parquet = test_parquet.drop([\"VendorID\",\"payment_type\",\"airport_fee\",\"mta_tax\",\"store_and_fwd_flag\",\"tip_amount\",\"tolls_amount\",\"congestion_surcharge\",\"RatecodeID\",\"extra\",\"improvement_surcharge\"],axis=1)\n",
    "\n",
    "test_parquet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2c094309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>Trip_Pickup_DateTime</th>\n",
       "      <th>Trip_Dropoff_DateTime</th>\n",
       "      <th>Passenger_Count</th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Start_Lon</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Rate_Code</th>\n",
       "      <th>store_and_forward</th>\n",
       "      <th>End_Lon</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>Payment_Type</th>\n",
       "      <th>Fare_Amt</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>Tip_Amt</th>\n",
       "      <th>Tolls_Amt</th>\n",
       "      <th>Total_Amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8641350</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2009-01-31 11:18:29</td>\n",
       "      <td>2009-01-31 11:21:48</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-73.976457</td>\n",
       "      <td>40.747957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.971745</td>\n",
       "      <td>40.754363</td>\n",
       "      <td>Cash</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11766750</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-01-13 00:40:00</td>\n",
       "      <td>2009-01-13 00:40:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-73.976517</td>\n",
       "      <td>40.739670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.982905</td>\n",
       "      <td>40.737033</td>\n",
       "      <td>Credit</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5638063</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-01-27 15:48:00</td>\n",
       "      <td>2009-01-27 15:56:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-73.960088</td>\n",
       "      <td>40.770650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.947710</td>\n",
       "      <td>40.775052</td>\n",
       "      <td>CASH</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12807019</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-01-16 00:37:00</td>\n",
       "      <td>2009-01-16 00:49:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.85</td>\n",
       "      <td>-73.976733</td>\n",
       "      <td>40.727008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.989447</td>\n",
       "      <td>40.756907</td>\n",
       "      <td>CASH</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4564006</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-01-18 12:49:00</td>\n",
       "      <td>2009-01-18 12:53:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-73.996273</td>\n",
       "      <td>40.727135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.990425</td>\n",
       "      <td>40.735417</td>\n",
       "      <td>CASH</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172978</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2009-01-03 21:00:40</td>\n",
       "      <td>2009-01-03 21:22:13</td>\n",
       "      <td>1</td>\n",
       "      <td>5.60</td>\n",
       "      <td>-73.991571</td>\n",
       "      <td>40.750335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-74.002687</td>\n",
       "      <td>40.707304</td>\n",
       "      <td>Cash</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10703920</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2009-01-08 16:28:05</td>\n",
       "      <td>2009-01-08 16:37:06</td>\n",
       "      <td>2</td>\n",
       "      <td>1.90</td>\n",
       "      <td>-73.967585</td>\n",
       "      <td>40.762756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.988478</td>\n",
       "      <td>40.778686</td>\n",
       "      <td>Cash</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552489</th>\n",
       "      <td>VTS</td>\n",
       "      <td>2009-01-02 22:29:00</td>\n",
       "      <td>2009-01-02 22:53:00</td>\n",
       "      <td>3</td>\n",
       "      <td>16.69</td>\n",
       "      <td>-73.789303</td>\n",
       "      <td>40.647080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.865262</td>\n",
       "      <td>40.837747</td>\n",
       "      <td>CASH</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9133006</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2009-01-28 18:39:02</td>\n",
       "      <td>2009-01-28 18:54:03</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>-74.004219</td>\n",
       "      <td>40.712982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-74.004461</td>\n",
       "      <td>40.740609</td>\n",
       "      <td>Cash</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7328583</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2009-01-17 13:18:13</td>\n",
       "      <td>2009-01-17 13:20:44</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-73.981240</td>\n",
       "      <td>40.780994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.977311</td>\n",
       "      <td>40.787833</td>\n",
       "      <td>Cash</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         vendor_name Trip_Pickup_DateTime Trip_Dropoff_DateTime  \\\n",
       "8641350          CMT  2009-01-31 11:18:29   2009-01-31 11:21:48   \n",
       "11766750         VTS  2009-01-13 00:40:00   2009-01-13 00:40:00   \n",
       "5638063          VTS  2009-01-27 15:48:00   2009-01-27 15:56:00   \n",
       "12807019         VTS  2009-01-16 00:37:00   2009-01-16 00:49:00   \n",
       "4564006          VTS  2009-01-18 12:49:00   2009-01-18 12:53:00   \n",
       "4172978          CMT  2009-01-03 21:00:40   2009-01-03 21:22:13   \n",
       "10703920         CMT  2009-01-08 16:28:05   2009-01-08 16:37:06   \n",
       "3552489          VTS  2009-01-02 22:29:00   2009-01-02 22:53:00   \n",
       "9133006          CMT  2009-01-28 18:39:02   2009-01-28 18:54:03   \n",
       "7328583          CMT  2009-01-17 13:18:13   2009-01-17 13:20:44   \n",
       "\n",
       "          Passenger_Count  Trip_Distance  Start_Lon  Start_Lat  Rate_Code  \\\n",
       "8641350                 1           0.50 -73.976457  40.747957        NaN   \n",
       "11766750                5           0.56 -73.976517  40.739670        NaN   \n",
       "5638063                 1           0.97 -73.960088  40.770650        NaN   \n",
       "12807019                1           2.85 -73.976733  40.727008        NaN   \n",
       "4564006                 1           0.82 -73.996273  40.727135        NaN   \n",
       "4172978                 1           5.60 -73.991571  40.750335        NaN   \n",
       "10703920                2           1.90 -73.967585  40.762756        NaN   \n",
       "3552489                 3          16.69 -73.789303  40.647080        NaN   \n",
       "9133006                 1           2.50 -74.004219  40.712982        NaN   \n",
       "7328583                 1           0.50 -73.981240  40.780994        NaN   \n",
       "\n",
       "          store_and_forward    End_Lon    End_Lat Payment_Type  Fare_Amt  \\\n",
       "8641350                 NaN -73.971745  40.754363         Cash       4.1   \n",
       "11766750                NaN -73.982905  40.737033       Credit       3.7   \n",
       "5638063                 NaN -73.947710  40.775052         CASH       6.1   \n",
       "12807019                NaN -73.989447  40.756907         CASH      10.5   \n",
       "4564006                 NaN -73.990425  40.735417         CASH       4.5   \n",
       "4172978                 NaN -74.002687  40.707304         Cash      17.4   \n",
       "10703920                NaN -73.988478  40.778686         Cash      13.9   \n",
       "3552489                 NaN -73.865262  40.837747         CASH      36.5   \n",
       "9133006                 NaN -74.004461  40.740609         Cash      11.1   \n",
       "7328583                 NaN -73.977311  40.787833         Cash       3.7   \n",
       "\n",
       "          surcharge  mta_tax  Tip_Amt  Tolls_Amt  Total_Amt  \n",
       "8641350         0.0      NaN      0.0        0.0        4.1  \n",
       "11766750        0.5      NaN      1.8        0.0        6.0  \n",
       "5638063         0.0      NaN      0.0        0.0        6.1  \n",
       "12807019        0.5      NaN      0.0        0.0       11.0  \n",
       "4564006         0.0      NaN      0.0        0.0        4.5  \n",
       "4172978         0.0      NaN      0.0        0.0       17.4  \n",
       "10703920        0.0      NaN      0.0        0.0       13.9  \n",
       "3552489         0.5      NaN      0.0        0.0       37.0  \n",
       "9133006         0.0      NaN      0.0        0.0       11.1  \n",
       "7328583         0.0      NaN      0.0        0.0        3.7  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_parquet1= get_and_clean_month_taxi_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2010-01.parquet')\n",
    "# test_parquet1 = test_parquet1.drop([\"vendor_id\",\"payment_type\",\"mta_tax\",\"store_and_fwd_flag\",\"tip_amount\",\"surcharge\",\"rate_code\",\"tolls_amount\"], axis = 1)\n",
    "\n",
    "# test_parquet1.head(10)\n",
    "\n",
    "test_parquet2= get_and_clean_month_taxi_data('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2009-01.parquet')\n",
    "\n",
    "test_parquet2.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "70efc681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_Pickup_DateTime</th>\n",
       "      <th>Trip_Dropoff_DateTime</th>\n",
       "      <th>Passenger_Count</th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Start_Lon</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>End_Lon</th>\n",
       "      <th>End_Lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8641350</th>\n",
       "      <td>2009-01-31 11:18:29</td>\n",
       "      <td>2009-01-31 11:21:48</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-73.976457</td>\n",
       "      <td>40.747957</td>\n",
       "      <td>-73.971745</td>\n",
       "      <td>40.754363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11766750</th>\n",
       "      <td>2009-01-13 00:40:00</td>\n",
       "      <td>2009-01-13 00:40:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-73.976517</td>\n",
       "      <td>40.739670</td>\n",
       "      <td>-73.982905</td>\n",
       "      <td>40.737033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5638063</th>\n",
       "      <td>2009-01-27 15:48:00</td>\n",
       "      <td>2009-01-27 15:56:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-73.960088</td>\n",
       "      <td>40.770650</td>\n",
       "      <td>-73.947710</td>\n",
       "      <td>40.775052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12807019</th>\n",
       "      <td>2009-01-16 00:37:00</td>\n",
       "      <td>2009-01-16 00:49:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.85</td>\n",
       "      <td>-73.976733</td>\n",
       "      <td>40.727008</td>\n",
       "      <td>-73.989447</td>\n",
       "      <td>40.756907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4564006</th>\n",
       "      <td>2009-01-18 12:49:00</td>\n",
       "      <td>2009-01-18 12:53:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-73.996273</td>\n",
       "      <td>40.727135</td>\n",
       "      <td>-73.990425</td>\n",
       "      <td>40.735417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172978</th>\n",
       "      <td>2009-01-03 21:00:40</td>\n",
       "      <td>2009-01-03 21:22:13</td>\n",
       "      <td>1</td>\n",
       "      <td>5.60</td>\n",
       "      <td>-73.991571</td>\n",
       "      <td>40.750335</td>\n",
       "      <td>-74.002687</td>\n",
       "      <td>40.707304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10703920</th>\n",
       "      <td>2009-01-08 16:28:05</td>\n",
       "      <td>2009-01-08 16:37:06</td>\n",
       "      <td>2</td>\n",
       "      <td>1.90</td>\n",
       "      <td>-73.967585</td>\n",
       "      <td>40.762756</td>\n",
       "      <td>-73.988478</td>\n",
       "      <td>40.778686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552489</th>\n",
       "      <td>2009-01-02 22:29:00</td>\n",
       "      <td>2009-01-02 22:53:00</td>\n",
       "      <td>3</td>\n",
       "      <td>16.69</td>\n",
       "      <td>-73.789303</td>\n",
       "      <td>40.647080</td>\n",
       "      <td>-73.865262</td>\n",
       "      <td>40.837747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9133006</th>\n",
       "      <td>2009-01-28 18:39:02</td>\n",
       "      <td>2009-01-28 18:54:03</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>-74.004219</td>\n",
       "      <td>40.712982</td>\n",
       "      <td>-74.004461</td>\n",
       "      <td>40.740609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7328583</th>\n",
       "      <td>2009-01-17 13:18:13</td>\n",
       "      <td>2009-01-17 13:20:44</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-73.981240</td>\n",
       "      <td>40.780994</td>\n",
       "      <td>-73.977311</td>\n",
       "      <td>40.787833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Trip_Pickup_DateTime Trip_Dropoff_DateTime  Passenger_Count  \\\n",
       "8641350   2009-01-31 11:18:29   2009-01-31 11:21:48                1   \n",
       "11766750  2009-01-13 00:40:00   2009-01-13 00:40:00                5   \n",
       "5638063   2009-01-27 15:48:00   2009-01-27 15:56:00                1   \n",
       "12807019  2009-01-16 00:37:00   2009-01-16 00:49:00                1   \n",
       "4564006   2009-01-18 12:49:00   2009-01-18 12:53:00                1   \n",
       "4172978   2009-01-03 21:00:40   2009-01-03 21:22:13                1   \n",
       "10703920  2009-01-08 16:28:05   2009-01-08 16:37:06                2   \n",
       "3552489   2009-01-02 22:29:00   2009-01-02 22:53:00                3   \n",
       "9133006   2009-01-28 18:39:02   2009-01-28 18:54:03                1   \n",
       "7328583   2009-01-17 13:18:13   2009-01-17 13:20:44                1   \n",
       "\n",
       "          Trip_Distance  Start_Lon  Start_Lat    End_Lon    End_Lat  \n",
       "8641350            0.50 -73.976457  40.747957 -73.971745  40.754363  \n",
       "11766750           0.56 -73.976517  40.739670 -73.982905  40.737033  \n",
       "5638063            0.97 -73.960088  40.770650 -73.947710  40.775052  \n",
       "12807019           2.85 -73.976733  40.727008 -73.989447  40.756907  \n",
       "4564006            0.82 -73.996273  40.727135 -73.990425  40.735417  \n",
       "4172978            5.60 -73.991571  40.750335 -74.002687  40.707304  \n",
       "10703920           1.90 -73.967585  40.762756 -73.988478  40.778686  \n",
       "3552489           16.69 -73.789303  40.647080 -73.865262  40.837747  \n",
       "9133006            2.50 -74.004219  40.712982 -74.004461  40.740609  \n",
       "7328583            0.50 -73.981240  40.780994 -73.977311  40.787833  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_parquet2=test_parquet2.drop([\"vendor_name\",\"Total_Amt\",\"Tolls_Amt\",\"store_and_forward\",\"Tip_Amt\",\"mta_tax\",\"surcharge\",\"Fare_Amt\",\"Payment_Type\",\"Rate_Code\",\"Passenger_Count\"], axis = 1)\n",
    "test_parquet2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "884672ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miles_to_km(distance_miles):\n",
    "    distance_km = distance_miles /0.62137119\n",
    "    return distance_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5df93585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Code in order to change the taxi zone to a latitude and longitude variable\n",
    "def get_lat_and_long_from_zone(zone):\n",
    "    import json\n",
    "    from shapely.geometry import Point\n",
    "    df = gpd.read_file('NYCTaxiZones.geojson')\n",
    "    taxi_zones = gpd.GeoDataFrame(df)\n",
    "    taxi_zones = taxi_zones.to_crs(4326)\n",
    "\n",
    "    taxi_zones['lon'] = taxi_zones.centroid.x  \n",
    "    taxi_zones['lat'] = taxi_zones.centroid.y\n",
    "    \n",
    "\n",
    "    for index,row in df.iterrows():\n",
    "        if zone == row[\"location_id\"]:\n",
    "            long = row['lon']\n",
    "            lat = row['lat']\n",
    "            return lat, long\n",
    "#test_parquet['pickup_lon','pickup_lat'] = test_parquet.apply(lambda x: get_lat_and_long_from_zone(x[\"PULocationID\"]), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a107f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zones_within_bbox():\n",
    "    import json\n",
    "    from shapely.geometry import Point\n",
    "    df = gpd.read_file('NYCTaxiZones.geojson')\n",
    "    taxi_zones = gpd.GeoDataFrame(df)\n",
    "    taxi_zones = taxi_zones.to_crs(4326)\n",
    "\n",
    "    taxi_zones['lon'] = taxi_zones.centroid.x  \n",
    "    taxi_zones['lat'] = taxi_zones.centroid.y\n",
    "\n",
    "    northlimit  = 40.908524\n",
    "    southlimit = 40.560445\n",
    "    eastlimit = -73.717047\n",
    "    westlimit = -74.242330\n",
    "\n",
    "    \n",
    "    taxi_zones = taxi_zones[(taxi_zones[\"lon\"] <= eastlimit) & (taxi_zones[\"lon\"] >= westlimit)] \n",
    "    taxi_zones = taxi_zones[(taxi_zones[\"lat\"] <= northlimit) & (taxi_zones[\"lat\"]>= southlimit)]\n",
    "\n",
    "    zones_in_range =list(taxi_zones[\"location_id\"])\n",
    "    \n",
    "    return zones_in_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data():\n",
    "    all_taxi_dataframes = []\n",
    "    all_csv_urls = find_taxi_parquet_urls()\n",
    "    northlimit  = 40.908524\n",
    "    southlimit = 40.560445\n",
    "    eastlimit = -73.717047\n",
    "    westlimit = -74.242330\n",
    "    for csv_url in all_csv_urls:\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_month_taxi_data(csv_url)\n",
    "        # Making sure that the zone is in the [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
    "        if 'PULocationID' in dataframe.columns:\n",
    "            dataframe[dataframe['PULocationID'].isin(zones_within_bbox())]\n",
    "            dataframe[dataframe['DOLocationID'].isin(zones_within_bbox())]\n",
    "            # Changing the distance column of each data set from miles to kilometers\n",
    "            dataframe['trip_distance'] = dataframe.apply(lambda x: x[\"trip_distance\"]/0.62137119, axis = 1)\n",
    "            # Adding A Pickup Hour Column to the Data\n",
    "            dataframe['pickup_hour'] = dataframe['tpep_pickup_datetime'].apply(lambda x:x.hour)\n",
    "            # Removing Unnecessary Columns:\n",
    "            dataframe = dataframe.drop([\"VendorID\",\"payment_type\",\"airport_fee\",\"mta_tax\",\"store_and_fwd_flag\",\"tip_amount\",\"tolls_amount\",\"congestion_surcharge\",\"RatecodeID\",\"extra\",\"improvement_surcharge\",\"fare_amount\",\"passenger_count\",\"total_amount\"],axis=1)\n",
    "\n",
    "            # Normalizing Column Names:\n",
    "            dataframe.rename(columns ={\"trip_distance\": \"distance\", \"tpep_pickup_datetime\": \"pickup_datetime\",\"tpep_dropoff_datetime\":\"dropoff_datetime\"}, inplace = True)\n",
    "        elif \"pickup_longitude\" in dataframe.columns:\n",
    "            \n",
    "            add_distance_column(dataframe)\n",
    "            \n",
    "            dataframe = dataframe[(dataframe[\"pickup_longitude\"] <= eastlimit) & (dataframe[\"pickup_longitude\"] >= westlimit)] \n",
    "            dataframe = dataframe [(dataframe [\"pickup_latitude\"] <= northlimit) & (dataframe[\"pickup_latitude\"]>= southlimit)]\n",
    "\n",
    "            dataframe  = dataframe[(dataframe[\"dropoff_longitude\"] <= eastlimit) & (dataframe[\"dropoff_longitude\"] >= westlimit)] \n",
    "            dataframe = dataframe[(dataframe[\"dropoff_latitude\"] <= northlimit) & (dataframe[\"dropoff_latitude\"]>= southlimit)]\n",
    "\n",
    "            #Cleaning the date to make Datetime Object (already datetime object?)\n",
    "            dataframe[\"dropoff_datetime\"]  = dataframe[\"dropoff_datetime\"].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))\n",
    "            dataframe[\"pickup_datetime\"]  = dataframe[\"pickup_datetime\"].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))\n",
    "            dataframe['pickup_hour'] = dataframe['pickup_datetime'].apply(lambda x:x.hour)\n",
    "\n",
    "            dataframe = dataframe.drop([\"vendor_id\",\"payment_type\",\"mta_tax\",\"store_and_fwd_flag\",\"tip_amount\",\"surcharge\",\"rate_code\",\"tolls_amount\",\"fare_amount\",\"passenger_count\",\"total_amount\"], axis = 1)\n",
    "            \n",
    "            # Normalizing Column Names\n",
    "            dataframe.rename(columns ={\"trip_distance\": \"distance\"}, inplace = True)\n",
    "\n",
    "        elif \"Trip_Pickup_DateTime\" in dataframe.columns:\n",
    "\n",
    "            dataframe.rename(columns ={\"Trip_Distance\": \"distance\",\"Start_Lon\":\"pickup_longitude\",\"Start_Lat\":\"pickup_latitude\",\"End_Lon\":\"dropoff_longitude\",\"End_Lat\":\"dropoff_latitude\"}, inplace = True)\n",
    "            dataframe = dataframe[(dataframe[\"pickup_longitude\"] <= eastlimit) & (dataframe[\"pickup_longitude\"] >= westlimit)] \n",
    "            dataframe = dataframe [(dataframe [\"pickup_latitude\"] <= northlimit) & (dataframe[\"pickup_latitude\"]>= southlimit)]\n",
    "\n",
    "            dataframe  = dataframe[(dataframe[\"dropoff_longitude\"] <= eastlimit) & (dataframe[\"dropoff_longitude\"] >= westlimit)] \n",
    "            dataframe = dataframe[(dataframe[\"dropoff_latitude\"] <= northlimit) & (dataframe[\"dropoff_latitude\"]>= southlimit)]\n",
    "\n",
    "\n",
    "            dataframe = dataframe.drop([\"vendor_name\",\"Total_Amt\",\"Tolls_Amt\",\"store_and_forward\",\"Tip_Amt\",\"mta_tax\",\"surcharge\",\"Fare_Amt\",\"Payment_Type\",\"Rate_Code\",\"Passenger_Count\"], axis = 1)\n",
    "            dataframe[\"Trip_Pickup_DateTime\"]  = dataframe[\"Trip_Pickup_DateTime\"].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))\n",
    "            dataframe[\"Trip_Dropoff_DateTime\"]  = dataframe[\"Trip_Dropoff_DateTime\"].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))\n",
    "            dataframe['pickup_hour'] = dataframe[\"Trip_Pickup_DateTime\"].apply(lambda x:x.hour)\n",
    "            \n",
    "            dataframe['distance'] = dataframe.apply(lambda x: x[\"distance\"]/0.62137119, axis = 1)\n",
    "\n",
    "            dataframe.rename(columns ={\"Trip_Pickup_DateTime\":\"pickup_datetime\",\"Trip_Dropoff_DateTime\":\"dropoff_datetime\"}, inplace = True)\n",
    "        else:\n",
    "            print(csv_url)\n",
    "        \n",
    "\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        \n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "    \n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff321bec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data\n",
    "\n",
    "In this portion of the project, two functions load_and_clean_uber_data() and get_uber_data() are used.  The function load_and_clean_uber_data() reads in the uber data from a csv file and returns a dataframe.  The function get_uber_data() uses the previous function to read in the data, then uses the function add_distance_column previously defined in order to add the distance in kilometers of each trip taken by an uber in the dataset and returns the uber data as a dataframe.  In addition, some additional processing was done ot the data to convert the pickup_datetime into a datetime object and create a column for the day of the week the pickup occured on.  In addition any data that is outside of the bounding box (http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047) was removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data(csv_file):\n",
    "    return pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    uber_dataframe = load_and_clean_uber_data(UBER_CSV)\n",
    "    add_distance_column(uber_dataframe)\n",
    "    # Making Pickup_datetime a datetime object\n",
    "    uber_dataframe[\"pickup_datetime\"]  = uber_dataframe[\"pickup_datetime\"].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d %H:%M:%S %Z'))\n",
    "    uber_dataframe[\"day_of_week\"]= uber_dataframe['pickup_datetime'].apply(lambda x: x.isoweekday())\n",
    "\n",
    "    # Removing any data outside of the [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
    "    #NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "    northlimit  = 40.908524\n",
    "    southlimit = 40.560445\n",
    "    eastlimit = -73.717047\n",
    "    westlimit = -74.242330\n",
    "    \n",
    "    uber_dataframe = uber_dataframe[(uber_dataframe[\"pickup_longitude\"] <= eastlimit) & (uber_dataframe[\"pickup_longitude\"] >= westlimit)] \n",
    "    uber_dataframe = uber_dataframe [(uber_dataframe [\"pickup_latitude\"] <= northlimit) & (uber_dataframe[\"pickup_latitude\"]>= southlimit)]\n",
    "\n",
    "    uber_dataframe  = uber_dataframe[(uber_dataframe[\"dropoff_longitude\"] <= eastlimit) & (uber_dataframe[\"dropoff_longitude\"] >= westlimit)] \n",
    "    uber_dataframe = uber_dataframe[(uber_dataframe[\"dropoff_latitude\"] <= northlimit) & (uber_dataframe[\"dropoff_latitude\"]>= southlimit)]\n",
    "\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data\n",
    "\n",
    "In processing the weather data, two different dataframes (hourly_weather_data, daily_weather_data) were created.  The daily dataframe has data for each day from January 2009 to June 2015 and any duplicate measurment for the days is dropped.  In the hourly data, the data is broken down to each hour of each day from January 2009 to June 2015 and it drops any duplicate measurments that are taken in a given hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    # Just need to read in the data as a measurment is taken each hour \n",
    "    all_data = pd.read_csv(csv_file)\n",
    "\n",
    "    # split data hourly\n",
    "    date = all_data['DATE']\n",
    "    import datetime\n",
    "    date = date.apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%dT%H:%M:%S'))\n",
    "    all_data['hours'] = date.apply(lambda x:x.hour)\n",
    "    all_data['newDATE'] = 0\n",
    "    for i in range(len(date)):\n",
    "        all_data['newDATE'][i] = all_data['DATE'][i][:10]\n",
    "    # now we have cleaned the data, now rename it\n",
    "    hourly_data = all_data\n",
    "\n",
    "    # you'll find which way to use in the later part\n",
    "    # combine them all together and split into 24 rows\n",
    "    # return clean_month_weather_data_hourly_all.drop_duplicates(subset=['hours'])\n",
    "\n",
    "    # split values into 24 rows for each day\n",
    "    return hourly_data.drop_duplicates(subset=['hours', 'newDATE'],keep='last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    #need to combine rows for each given day\n",
    "    all_data = pd.read_csv(csv_file)\n",
    "\n",
    "    # split data daily\n",
    "    date = all_data['DATE']\n",
    "    import datetime\n",
    "    date = date.apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%dT%H:%M:%S'))\n",
    "    all_data['days'] = date.apply(lambda x:x.day)\n",
    "    all_data['newDATE'] = 0\n",
    "    for i in range(len(date)):\n",
    "        all_data['newDATE'][i] = all_data['DATE'][i][:7]\n",
    "    # now we have cleaned the data, now rename it\n",
    "    daily_data = all_data\n",
    "\n",
    "    # you'll find which way to use in the later part\n",
    "    # combine them all together and split into 31 rows\n",
    "    # return clean_month_weather_data_hourly_all.drop_duplicates(subset=['hours'])\n",
    "\n",
    "    # split values into 31/30 rows for each month\n",
    "    return daily_data.drop_duplicates(subset=['days', 'newDATE'],keep='last')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "\n",
    "    # add this at the beginnig\n",
    "    # weather csv data file\n",
    "    # 2009_weather to 2015_weather (just pick the first 6 months)\n",
    "    csv__= '/Users/morax/Documents/哥大/IEORE4501/IEOR4501 HW/IEOR4501 Project/'\n",
    "    csv09_file = csv__ + '2009_weather.csv'\n",
    "    csv10_file = csv__ + '2010_weather.csv'\n",
    "    csv11_file = csv__ + '2011_weather.csv'\n",
    "    csv12_file = csv__ + '2012_weather.csv'\n",
    "    csv13_file = csv__ + '2013_weather.csv'\n",
    "    csv14_file = csv__ + '2014_weather.csv'\n",
    "    csv15_file = csv__ + '2015_weather.csv'\n",
    "    weather_csv09_14_files = [csv09_file, csv10_file, csv11_file, csv12_file, csv13_file, csv14_file]\n",
    "    \n",
    "    for csv_file in weather_csv09_14_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "    hourly_15_dataframe = clean_month_weather_data_hourly(csv15_file).iloc[:4344]\n",
    "    hourly_dataframes.append(hourly_15_dataframe)\n",
    "    daily_15_dataframe = clean_month_weather_data_daily(csv15_file).iloc[:181]\n",
    "    daily_dataframes.append(daily_15_dataframe)\n",
    "\n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes).reset_index(drop=True)\n",
    "    daily_data = pd.concat(daily_dataframes).reset_index(drop=True)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900f7aa",
   "metadata": {},
   "source": [
    "### Process All Data\n",
    "\n",
    "Once all of the functions in order to process the data have been written each of those functions can be executed.  Executing each of these functions, provides four clean data sets, taxi_data, uber_data, hourly_weather_data, and daily_weather_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:17: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lon'] = taxi_zones.centroid.x\n",
      "/var/folders/bx/vxcv_d0d4mvb9fjsgycq43yr0000gn/T/ipykernel_20385/394976474.py:18: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  taxi_zones['lat'] = taxi_zones.centroid.y\n"
     ]
    }
   ],
   "source": [
    "taxi_data = get_and_clean_taxi_data()\n",
    "#uber_data = get_uber_data()\n",
    "#hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37437cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>Distance</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24238194</td>\n",
       "      <td>2015-05-07 19:52:06.0000003</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "      <td>1.682054</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27835199</td>\n",
       "      <td>2009-07-17 20:04:56.0000002</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "      <td>2.455737</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44984355</td>\n",
       "      <td>2009-08-24 21:45:00.00000061</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "      <td>5.032581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25894730</td>\n",
       "      <td>2009-06-26 08:22:21.0000001</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "      <td>1.660431</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17610152</td>\n",
       "      <td>2014-08-28 17:47:00.000000188</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "      <td>4.472077</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44470845</td>\n",
       "      <td>2011-02-12 02:27:09.0000006</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2011-02-12 02:27:09</td>\n",
       "      <td>-73.969019</td>\n",
       "      <td>40.755910</td>\n",
       "      <td>-73.969019</td>\n",
       "      <td>40.755910</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48725865</td>\n",
       "      <td>2014-10-12 07:04:00.0000002</td>\n",
       "      <td>24.5</td>\n",
       "      <td>2014-10-12 07:04:00</td>\n",
       "      <td>-73.961447</td>\n",
       "      <td>40.693965</td>\n",
       "      <td>-73.871195</td>\n",
       "      <td>40.774297</td>\n",
       "      <td>5</td>\n",
       "      <td>11.722174</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15822268</td>\n",
       "      <td>2012-02-17 09:32:00.00000043</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2012-02-17 09:32:00</td>\n",
       "      <td>-73.975187</td>\n",
       "      <td>40.745767</td>\n",
       "      <td>-74.002720</td>\n",
       "      <td>40.743537</td>\n",
       "      <td>1</td>\n",
       "      <td>2.330953</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50611056</td>\n",
       "      <td>2012-03-29 19:06:00.000000273</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2012-03-29 19:06:00</td>\n",
       "      <td>-74.001065</td>\n",
       "      <td>40.741787</td>\n",
       "      <td>-73.963040</td>\n",
       "      <td>40.775012</td>\n",
       "      <td>1</td>\n",
       "      <td>4.885731</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2205147</td>\n",
       "      <td>2015-05-22 17:32:27.0000004</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2015-05-22 17:32:27</td>\n",
       "      <td>-73.974388</td>\n",
       "      <td>40.746952</td>\n",
       "      <td>-73.988586</td>\n",
       "      <td>40.729805</td>\n",
       "      <td>1</td>\n",
       "      <td>2.249161</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                            key  fare_amount  \\\n",
       "0     24238194    2015-05-07 19:52:06.0000003          7.5   \n",
       "1     27835199    2009-07-17 20:04:56.0000002          7.7   \n",
       "2     44984355   2009-08-24 21:45:00.00000061         12.9   \n",
       "3     25894730    2009-06-26 08:22:21.0000001          5.3   \n",
       "4     17610152  2014-08-28 17:47:00.000000188         16.0   \n",
       "5     44470845    2011-02-12 02:27:09.0000006          4.9   \n",
       "6     48725865    2014-10-12 07:04:00.0000002         24.5   \n",
       "8     15822268   2012-02-17 09:32:00.00000043          9.7   \n",
       "9     50611056  2012-03-29 19:06:00.000000273         12.5   \n",
       "10     2205147    2015-05-22 17:32:27.0000004          6.5   \n",
       "\n",
       "       pickup_datetime  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0  2015-05-07 19:52:06        -73.999817        40.738354         -73.999512   \n",
       "1  2009-07-17 20:04:56        -73.994355        40.728225         -73.994710   \n",
       "2  2009-08-24 21:45:00        -74.005043        40.740770         -73.962565   \n",
       "3  2009-06-26 08:22:21        -73.976124        40.790844         -73.965316   \n",
       "4  2014-08-28 17:47:00        -73.925023        40.744085         -73.973082   \n",
       "5  2011-02-12 02:27:09        -73.969019        40.755910         -73.969019   \n",
       "6  2014-10-12 07:04:00        -73.961447        40.693965         -73.871195   \n",
       "8  2012-02-17 09:32:00        -73.975187        40.745767         -74.002720   \n",
       "9  2012-03-29 19:06:00        -74.001065        40.741787         -73.963040   \n",
       "10 2015-05-22 17:32:27        -73.974388        40.746952         -73.988586   \n",
       "\n",
       "    dropoff_latitude  passenger_count   Distance  day_of_week  \n",
       "0          40.723217                1   1.682054            4  \n",
       "1          40.750325                1   2.455737            5  \n",
       "2          40.772647                1   5.032581            1  \n",
       "3          40.803349                3   1.660431            5  \n",
       "4          40.761247                5   4.472077            4  \n",
       "5          40.755910                1   0.000000            6  \n",
       "6          40.774297                5  11.722174            7  \n",
       "8          40.743537                1   2.330953            5  \n",
       "9          40.775012                1   4.885731            4  \n",
       "10         40.729805                1   2.249161            5  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f58a8a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>distance</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10566313</th>\n",
       "      <td>2015-01-26 00:57:34</td>\n",
       "      <td>2015-01-26 01:06:47</td>\n",
       "      <td>3.862426</td>\n",
       "      <td>164.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100166</th>\n",
       "      <td>2015-01-17 21:43:25</td>\n",
       "      <td>2015-01-17 21:47:11</td>\n",
       "      <td>1.287475</td>\n",
       "      <td>234.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332144</th>\n",
       "      <td>2015-01-01 20:37:28</td>\n",
       "      <td>2015-01-01 20:48:13</td>\n",
       "      <td>2.156521</td>\n",
       "      <td>142.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841470</th>\n",
       "      <td>2015-01-03 10:43:15</td>\n",
       "      <td>2015-01-03 10:50:28</td>\n",
       "      <td>4.538350</td>\n",
       "      <td>229.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6119963</th>\n",
       "      <td>2015-01-15 20:31:59</td>\n",
       "      <td>2015-01-15 20:36:17</td>\n",
       "      <td>1.303569</td>\n",
       "      <td>249.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8807639</th>\n",
       "      <td>2015-01-22 06:50:02</td>\n",
       "      <td>2015-01-22 06:55:14</td>\n",
       "      <td>1.931213</td>\n",
       "      <td>239.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193240</th>\n",
       "      <td>2015-01-09 09:03:50</td>\n",
       "      <td>2015-01-09 09:20:19</td>\n",
       "      <td>2.735885</td>\n",
       "      <td>24.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12323399</th>\n",
       "      <td>2015-01-31 07:50:47</td>\n",
       "      <td>2015-01-31 07:54:26</td>\n",
       "      <td>0.772485</td>\n",
       "      <td>164.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697863</th>\n",
       "      <td>2015-01-12 16:42:51</td>\n",
       "      <td>2015-01-12 17:21:29</td>\n",
       "      <td>9.495130</td>\n",
       "      <td>186.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11030186</th>\n",
       "      <td>2015-01-28 10:37:55</td>\n",
       "      <td>2015-01-28 10:46:09</td>\n",
       "      <td>1.689811</td>\n",
       "      <td>237.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pickup_datetime    dropoff_datetime  distance  PULocationID  \\\n",
       "10566313 2015-01-26 00:57:34 2015-01-26 01:06:47  3.862426         164.0   \n",
       "7100166  2015-01-17 21:43:25 2015-01-17 21:47:11  1.287475         234.0   \n",
       "332144   2015-01-01 20:37:28 2015-01-01 20:48:13  2.156521         142.0   \n",
       "841470   2015-01-03 10:43:15 2015-01-03 10:50:28  4.538350         229.0   \n",
       "6119963  2015-01-15 20:31:59 2015-01-15 20:36:17  1.303569         249.0   \n",
       "8807639  2015-01-22 06:50:02 2015-01-22 06:55:14  1.931213         239.0   \n",
       "3193240  2015-01-09 09:03:50 2015-01-09 09:20:19  2.735885          24.0   \n",
       "12323399 2015-01-31 07:50:47 2015-01-31 07:54:26  0.772485         164.0   \n",
       "4697863  2015-01-12 16:42:51 2015-01-12 17:21:29  9.495130         186.0   \n",
       "11030186 2015-01-28 10:37:55 2015-01-28 10:46:09  1.689811         237.0   \n",
       "\n",
       "          DOLocationID  pickup_hour  pickup_longitude  pickup_latitude  \\\n",
       "10566313          79.0            0               NaN              NaN   \n",
       "7100166           90.0           21               NaN              NaN   \n",
       "332144           161.0           20               NaN              NaN   \n",
       "841470           148.0           10               NaN              NaN   \n",
       "6119963          114.0           20               NaN              NaN   \n",
       "8807639          142.0            6               NaN              NaN   \n",
       "3193240          143.0            9               NaN              NaN   \n",
       "12323399         170.0            7               NaN              NaN   \n",
       "4697863            7.0           16               NaN              NaN   \n",
       "11030186         162.0           10               NaN              NaN   \n",
       "\n",
       "          dropoff_longitude  dropoff_latitude  Distance  \n",
       "10566313                NaN               NaN       NaN  \n",
       "7100166                 NaN               NaN       NaN  \n",
       "332144                  NaN               NaN       NaN  \n",
       "841470                  NaN               NaN       NaN  \n",
       "6119963                 NaN               NaN       NaN  \n",
       "8807639                 NaN               NaN       NaN  \n",
       "3193240                 NaN               NaN       NaN  \n",
       "12323399                NaN               NaN       NaN  \n",
       "4697863                 NaN               NaN       NaN  \n",
       "11030186                NaN               NaN       NaN  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "17f1ac33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>REPORT_TYPE</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>HourlyAltimeterSetting</th>\n",
       "      <th>HourlyDewPointTemperature</th>\n",
       "      <th>...</th>\n",
       "      <th>BackupDistanceUnit</th>\n",
       "      <th>BackupElements</th>\n",
       "      <th>BackupElevation</th>\n",
       "      <th>BackupEquipment</th>\n",
       "      <th>BackupLatitude</th>\n",
       "      <th>BackupLongitude</th>\n",
       "      <th>BackupName</th>\n",
       "      <th>WindEquipmentChangeDate</th>\n",
       "      <th>hours</th>\n",
       "      <th>newDATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-01T00:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-01T01:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-01T02:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-01T03:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>3</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-01T04:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>4</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-01T05:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>5</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-01T06:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>6</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-01T07:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-01T08:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>8</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-01T09:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>9</td>\n",
       "      <td>2009-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION                 DATE  LATITUDE  LONGITUDE  ELEVATION  \\\n",
       "0  72505394728  2009-01-01T00:51:00  40.77898  -73.96925       42.7   \n",
       "1  72505394728  2009-01-01T01:51:00  40.77898  -73.96925       42.7   \n",
       "2  72505394728  2009-01-01T02:51:00  40.77898  -73.96925       42.7   \n",
       "3  72505394728  2009-01-01T03:51:00  40.77898  -73.96925       42.7   \n",
       "4  72505394728  2009-01-01T04:51:00  40.77898  -73.96925       42.7   \n",
       "5  72505394728  2009-01-01T05:51:00  40.77898  -73.96925       42.7   \n",
       "6  72505394728  2009-01-01T06:51:00  40.77898  -73.96925       42.7   \n",
       "7  72505394728  2009-01-01T07:51:00  40.77898  -73.96925       42.7   \n",
       "8  72505394728  2009-01-01T08:51:00  40.77898  -73.96925       42.7   \n",
       "9  72505394728  2009-01-01T09:51:00  40.77898  -73.96925       42.7   \n",
       "\n",
       "                          NAME REPORT_TYPE SOURCE HourlyAltimeterSetting  \\\n",
       "0  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.01   \n",
       "1  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.03   \n",
       "2  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.07   \n",
       "3  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.09   \n",
       "4  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.12   \n",
       "5  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.16   \n",
       "6  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.20   \n",
       "7  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.25   \n",
       "8  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.26   \n",
       "9  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.29   \n",
       "\n",
       "  HourlyDewPointTemperature  ... BackupDistanceUnit BackupElements  \\\n",
       "0                       3.0  ...                 mi           SNOW   \n",
       "1                       3.0  ...                 mi           SNOW   \n",
       "2                       3.0  ...                 mi           SNOW   \n",
       "3                       3.0  ...                 mi           SNOW   \n",
       "4                       3.0  ...                 mi           SNOW   \n",
       "5                       0.0  ...                 mi           SNOW   \n",
       "6                       0.0  ...                 mi           SNOW   \n",
       "7                       0.0  ...                 mi           SNOW   \n",
       "8                       0.0  ...                 mi           SNOW   \n",
       "9                       0.0  ...                 mi           SNOW   \n",
       "\n",
       "  BackupElevation BackupEquipment  BackupLatitude  BackupLongitude  \\\n",
       "0             NaN       SNOWBOARD             NaN              NaN   \n",
       "1             NaN       SNOWBOARD             NaN              NaN   \n",
       "2             NaN       SNOWBOARD             NaN              NaN   \n",
       "3             NaN       SNOWBOARD             NaN              NaN   \n",
       "4             NaN       SNOWBOARD             NaN              NaN   \n",
       "5             NaN       SNOWBOARD             NaN              NaN   \n",
       "6             NaN       SNOWBOARD             NaN              NaN   \n",
       "7             NaN       SNOWBOARD             NaN              NaN   \n",
       "8             NaN       SNOWBOARD             NaN              NaN   \n",
       "9             NaN       SNOWBOARD             NaN              NaN   \n",
       "\n",
       "         BackupName WindEquipmentChangeDate hours     newDATE  \n",
       "0  CENTRAL PARK ZOO              2006-09-18     0  2009-01-01  \n",
       "1  CENTRAL PARK ZOO              2006-09-18     1  2009-01-01  \n",
       "2  CENTRAL PARK ZOO              2006-09-18     2  2009-01-01  \n",
       "3  CENTRAL PARK ZOO              2006-09-18     3  2009-01-01  \n",
       "4  CENTRAL PARK ZOO              2006-09-18     4  2009-01-01  \n",
       "5  CENTRAL PARK ZOO              2006-09-18     5  2009-01-01  \n",
       "6  CENTRAL PARK ZOO              2006-09-18     6  2009-01-01  \n",
       "7  CENTRAL PARK ZOO              2006-09-18     7  2009-01-01  \n",
       "8  CENTRAL PARK ZOO              2006-09-18     8  2009-01-01  \n",
       "9  CENTRAL PARK ZOO              2006-09-18     9  2009-01-01  \n",
       "\n",
       "[10 rows x 125 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4ffc48db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>REPORT_TYPE</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>HourlyAltimeterSetting</th>\n",
       "      <th>HourlyDewPointTemperature</th>\n",
       "      <th>...</th>\n",
       "      <th>BackupDistanceUnit</th>\n",
       "      <th>BackupElements</th>\n",
       "      <th>BackupElevation</th>\n",
       "      <th>BackupEquipment</th>\n",
       "      <th>BackupLatitude</th>\n",
       "      <th>BackupLongitude</th>\n",
       "      <th>BackupName</th>\n",
       "      <th>WindEquipmentChangeDate</th>\n",
       "      <th>days</th>\n",
       "      <th>newDATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-01T23:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-02T23:59:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>SOD</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-03T23:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.08</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>3</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-04T23:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>4</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-05T23:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>5</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-06T23:59:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>SOD</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>6</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-07T23:59:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>SOD</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>7</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-08T23:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>29.73</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>8</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-09T23:51:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>4</td>\n",
       "      <td>30.26</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>9</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72505394728</td>\n",
       "      <td>2009-01-10T23:59:00</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>42.7</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>SOD</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>mi</td>\n",
       "      <td>SNOW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SNOWBOARD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRAL PARK ZOO</td>\n",
       "      <td>2006-09-18</td>\n",
       "      <td>10</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION                 DATE  LATITUDE  LONGITUDE  ELEVATION  \\\n",
       "0  72505394728  2009-01-01T23:51:00  40.77898  -73.96925       42.7   \n",
       "1  72505394728  2009-01-02T23:59:00  40.77898  -73.96925       42.7   \n",
       "2  72505394728  2009-01-03T23:51:00  40.77898  -73.96925       42.7   \n",
       "3  72505394728  2009-01-04T23:51:00  40.77898  -73.96925       42.7   \n",
       "4  72505394728  2009-01-05T23:51:00  40.77898  -73.96925       42.7   \n",
       "5  72505394728  2009-01-06T23:59:00  40.77898  -73.96925       42.7   \n",
       "6  72505394728  2009-01-07T23:59:00  40.77898  -73.96925       42.7   \n",
       "7  72505394728  2009-01-08T23:51:00  40.77898  -73.96925       42.7   \n",
       "8  72505394728  2009-01-09T23:51:00  40.77898  -73.96925       42.7   \n",
       "9  72505394728  2009-01-10T23:59:00  40.77898  -73.96925       42.7   \n",
       "\n",
       "                          NAME REPORT_TYPE SOURCE HourlyAltimeterSetting  \\\n",
       "0  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.22   \n",
       "1  NY CITY CENTRAL PARK, NY US       SOD        O                    NaN   \n",
       "2  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.08   \n",
       "3  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.00   \n",
       "4  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.03   \n",
       "5  NY CITY CENTRAL PARK, NY US       SOD        O                    NaN   \n",
       "6  NY CITY CENTRAL PARK, NY US       SOD        O                    NaN   \n",
       "7  NY CITY CENTRAL PARK, NY US       AUTO       4                  29.73   \n",
       "8  NY CITY CENTRAL PARK, NY US       AUTO       4                  30.26   \n",
       "9  NY CITY CENTRAL PARK, NY US       SOD        O                    NaN   \n",
       "\n",
       "  HourlyDewPointTemperature  ... BackupDistanceUnit BackupElements  \\\n",
       "0                       1.0  ...                 mi           SNOW   \n",
       "1                       NaN  ...                 mi           SNOW   \n",
       "2                       9.0  ...                 mi           SNOW   \n",
       "3                      12.0  ...                 mi           SNOW   \n",
       "4                       3.0  ...                 mi           SNOW   \n",
       "5                       NaN  ...                 mi           SNOW   \n",
       "6                       NaN  ...                 mi           SNOW   \n",
       "7                      16.0  ...                 mi           SNOW   \n",
       "8                      12.0  ...                 mi           SNOW   \n",
       "9                       NaN  ...                 mi           SNOW   \n",
       "\n",
       "  BackupElevation BackupEquipment  BackupLatitude  BackupLongitude  \\\n",
       "0             NaN       SNOWBOARD             NaN              NaN   \n",
       "1             NaN       SNOWBOARD             NaN              NaN   \n",
       "2             NaN       SNOWBOARD             NaN              NaN   \n",
       "3             NaN       SNOWBOARD             NaN              NaN   \n",
       "4             NaN       SNOWBOARD             NaN              NaN   \n",
       "5             NaN       SNOWBOARD             NaN              NaN   \n",
       "6             NaN       SNOWBOARD             NaN              NaN   \n",
       "7             NaN       SNOWBOARD             NaN              NaN   \n",
       "8             NaN       SNOWBOARD             NaN              NaN   \n",
       "9             NaN       SNOWBOARD             NaN              NaN   \n",
       "\n",
       "         BackupName WindEquipmentChangeDate days  newDATE  \n",
       "0  CENTRAL PARK ZOO              2006-09-18    1  2009-01  \n",
       "1  CENTRAL PARK ZOO              2006-09-18    2  2009-01  \n",
       "2  CENTRAL PARK ZOO              2006-09-18    3  2009-01  \n",
       "3  CENTRAL PARK ZOO              2006-09-18    4  2009-01  \n",
       "4  CENTRAL PARK ZOO              2006-09-18    5  2009-01  \n",
       "5  CENTRAL PARK ZOO              2006-09-18    6  2009-01  \n",
       "6  CENTRAL PARK ZOO              2006-09-18    7  2009-01  \n",
       "7  CENTRAL PARK ZOO              2006-09-18    8  2009-01  \n",
       "8  CENTRAL PARK ZOO              2006-09-18    9  2009-01  \n",
       "9  CENTRAL PARK ZOO              2006-09-18   10  2009-01  \n",
       "\n",
       "[10 rows x 125 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data\n",
    "\n",
    "Once the data was read and cleaned it is stored in a SQL database. In this portion, four tables (hourly_weather, daily_weather, taxi_trips, and uber_trips) were created to store the different dataframes data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)\n",
    "# First, using SQLAlchemy, create a SQLite database with which you’ll load in your preprocessed datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS hourly_weather\n",
    "    (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    DATE DATE,\n",
    "    LATITUDE FLOAT,\n",
    "    LONGITUDE FLOAT,\n",
    "    NAME TEXT,\n",
    "    HourlyWindDirection INTEGER,\n",
    "    HourlyWindGustSpeed FLOAT,\n",
    "    HourlyWindSpeed\tFLOAT,\n",
    "    hours INTEGER,\n",
    "    newDATE DATE\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS daily_weather\n",
    "    (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    DATE DATE,\n",
    "    LATITUDE FLOAT,\n",
    "    LONGITUDE FLOAT,\n",
    "    NAME TEXT,\n",
    "    days INTEGER,\n",
    "    newDATE YEAR MONTH\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi_trips\n",
    "    (id INTEGER PRIMARY KEY AUTOINCREMENT,\t\n",
    "    pickup_datetime\tDATE,\n",
    "    dropoff_datetime DATE,\n",
    "    passenger_count\tINTEGER,\n",
    "    distance FLOAT,\n",
    "    pickup_longitude FLOAT,\n",
    "    pickup_latitude FLOAT,\n",
    "    dropoff_longitude FLOAT,\n",
    "    dropoff_latitude FLOAT\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS uber_trips\n",
    "    (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    fare_amount\tFLOAT,\n",
    "    pickup_datetime DATE,\n",
    "    pickup_longitude FLOAT,\n",
    "    pickup_latitude FLOAT,\n",
    "    dropoff_longitude FLOAT,\n",
    "    dropoff_latitude FLOAT,\n",
    "    passenger_count INTEGER,\n",
    "    Distance FLOAT,\n",
    "    day_of_week INTEGER\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    engine.connect().execute(\n",
    "        HOURLY_WEATHER_SCHEMA\n",
    "    )\n",
    "    engine.connect().execute(\n",
    "        DAILY_WEATHER_SCHEMA\n",
    "    )\n",
    "    engine.connect().execute(\n",
    "        TAXI_TRIPS_SCHEMA\n",
    "    )\n",
    "    engine.connect().execute(\n",
    "        UBER_TRIPS_SCHEMA\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f527aa4",
   "metadata": {},
   "source": [
    "pd.read_sql_query - read data from querying a SQL table\n",
    "\n",
    "pd.read_sql_table - read entire SQL table\n",
    "\n",
    "df.to_sql - add data from the dataframe to a SQL table\n",
    "\n",
    "pd.to_numeric - Convert argument to a numeric type\n",
    "\n",
    "pd.concat - Concatenate pandas objects along a particular axis with optional set logic along the other axes\n",
    "\n",
    "pd.merge - Merge DataFrame or named Series objects with a database-style join\n",
    "\n",
    "pd.merge_asof - Perform a merge by key distance. This is similar to a left-join except that we match on the nearest key rather than equal keys. Both DataFrames must be sorted by the key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    for item_0, item_1 in table_to_df_dict.items():\n",
    "        # add data from the dataframe to a SQL table\n",
    "        item_1.to_sql(item_0, engine, index_label=\"id\", if_exists=\"append\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e6d3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data_clean = taxi_data.iloc[:,[1, 2, 3,4, 21, 22, 23, 25, 26]]\n",
    "uber_data_clean = uber_data.iloc[:,2:11]\n",
    "hourly_data = hourly_weather_data.iloc[:, [1,2,3,5,21,22,23,-2,-1]]\n",
    "daily_data = daily_weather_data.iloc[:, [1,2,3,5,-2,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1158824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data_clean = taxi_data_clean.set_index([pd.Series(np.arange(len(taxi_data['passenger_count'])))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_table_name_to_dataframe = {\n",
    "#     \"taxi_trips\": taxi_data_clean,\n",
    "#     \"uber_trips\": uber_data_clean,\n",
    "#     \"hourly_weather\": hourly_data,\n",
    "#     \"daily_weather\": daily_data,\n",
    "# }\n",
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_data,\n",
    "   \"daily_weather\": daily_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "74004f96",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) table taxi_trips has no column named distance\n[SQL: INSERT INTO taxi_trips (id, pickup_datetime, dropoff_datetime, passenger_count, distance, \"PULocationID\", \"DOLocationID\", fare_amount, total_amount, pickup_hour, pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, \"Distance\", vendor_name, \"Trip_Pickup_DateTime\", \"Trip_Dropoff_DateTime\", \"Passenger_Count\", \"Trip_Distance\", \"Start_Lon\", \"Start_Lat\", \"Rate_Code\", store_and_forward, \"End_Lon\", \"End_Lat\", \"Payment_Type\", \"Fare_Amt\", surcharge, mta_tax, \"Tip_Amt\", \"Tolls_Amt\", \"Total_Amt\") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)]\n[parameters: ((10566313, '2015-01-26 00:57:34.000000', '2015-01-26 01:06:47.000000', 1.0, 3.862425613907204, 164.0, 79.0, 10.0, 12.8, 0.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), (7100166, '2015-01-17 21:43:25.000000', '2015-01-17 21:47:11.000000', 1.0, 1.287475204635735, 234.0, 90.0, 4.5, 7.25, 21.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), (332144, '2015-01-01 20:37:28.000000', '2015-01-01 20:48:13.000000', 3.0, 2.156520967764856, 142.0, 161.0, 8.5, 9.8, 20.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), (841470, '2015-01-03 10:43:15.000000', '2015-01-03 10:50:28.000000', 1.0, 4.538350096340965, 229.0, 148.0, 9.5, 11.9, 10.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), (6119963, '2015-01-15 20:31:59.000000', '2015-01-15 20:36:17.000000', 1.0, 1.3035686446936816, 249.0, 114.0, 5.0, 7.68, 20.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), (8807639, '2015-01-22 06:50:02.000000', '2015-01-22 06:55:14.000000', 1.0, 1.931212806953602, 239.0, 142.0, 6.5, 7.3, 6.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), (3193240, '2015-01-09 09:03:50.000000', '2015-01-09 09:20:19.000000', 1.0, 2.7358848098509365, 24.0, 143.0, 11.5, 12.3, 9.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), (12323399, '2015-01-31 07:50:47.000000', '2015-01-31 07:54:26.000000', 1.0, 0.7724851227814409, 164.0, 170.0, 4.5, 6.3, 7.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None)  ... displaying 10 of 1793755 total bound parameter sets ...  (10714323, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'VTS', '2009-12-20 08:09:00', '2009-12-20 08:17:00', 1.0, 1.4, -73.985347, 40.758908, None, None, -73.97394, 40.764715, 'Credit', 6.5, 0.0, 0.5, 3.0, 0.0, 10.0), (5535768, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'VTS', '2009-12-14 09:18:00', '2009-12-14 09:39:00', 2.0, 7.36, -73.962407, 40.767188, None, None, -74.01495, 40.711175, 'Credit', 20.1, 0.0, 0.5, 3.5, 0.0, 24.1))]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1788\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1787\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1788\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_executemany(\n\u001b[1;32m   1789\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1790\u001b[0m         )\n\u001b[1;32m   1791\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameters \u001b[39mand\u001b[39;00m context\u001b[39m.\u001b[39mno_parameters:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/default.py:729\u001b[0m, in \u001b[0;36mDefaultDialect.do_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_executemany\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 729\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecutemany(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: table taxi_trips has no column named distance",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project Scaffolding.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m write_dataframes_to_table(map_table_name_to_dataframe)\n",
      "\u001b[1;32m/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project Scaffolding.ipynb Cell 44\u001b[0m in \u001b[0;36mwrite_dataframes_to_table\u001b[0;34m(table_to_df_dict)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrite_dataframes_to_table\u001b[39m(table_to_df_dict):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#X63sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mfor\u001b[39;00m item_0, item_1 \u001b[39min\u001b[39;00m table_to_df_dict\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#X63sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39m# add data from the dataframe to a SQL table\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#X63sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         item_1\u001b[39m.\u001b[39;49mto_sql(item_0, engine, index_label\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m\"\u001b[39;49m, if_exists\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mappend\u001b[39;49m\u001b[39m\"\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:2951\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2794\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2795\u001b[0m \u001b[39mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2796\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2947\u001b[0m \u001b[39m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   2948\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa:E501\u001b[39;00m\n\u001b[1;32m   2949\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m sql\n\u001b[0;32m-> 2951\u001b[0m \u001b[39mreturn\u001b[39;00m sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[1;32m   2952\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2953\u001b[0m     name,\n\u001b[1;32m   2954\u001b[0m     con,\n\u001b[1;32m   2955\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m   2956\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m   2957\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   2958\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   2959\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   2960\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   2961\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   2962\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:698\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(frame, DataFrame):\n\u001b[1;32m    694\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    695\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument should be either a Series or a DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    696\u001b[0m     )\n\u001b[0;32m--> 698\u001b[0m \u001b[39mreturn\u001b[39;00m pandas_sql\u001b[39m.\u001b[39;49mto_sql(\n\u001b[1;32m    699\u001b[0m     frame,\n\u001b[1;32m    700\u001b[0m     name,\n\u001b[1;32m    701\u001b[0m     if_exists\u001b[39m=\u001b[39;49mif_exists,\n\u001b[1;32m    702\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    703\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m    704\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m    705\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m    706\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    707\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    708\u001b[0m     engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    709\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mengine_kwargs,\n\u001b[1;32m    710\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:1742\u001b[0m, in \u001b[0;36mSQLDatabase.to_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1730\u001b[0m sql_engine \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m   1732\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_table(\n\u001b[1;32m   1733\u001b[0m     frame\u001b[39m=\u001b[39mframe,\n\u001b[1;32m   1734\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1740\u001b[0m )\n\u001b[0;32m-> 1742\u001b[0m total_inserted \u001b[39m=\u001b[39m sql_engine\u001b[39m.\u001b[39;49minsert_records(\n\u001b[1;32m   1743\u001b[0m     table\u001b[39m=\u001b[39;49mtable,\n\u001b[1;32m   1744\u001b[0m     con\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnectable,\n\u001b[1;32m   1745\u001b[0m     frame\u001b[39m=\u001b[39;49mframe,\n\u001b[1;32m   1746\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1747\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   1748\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m   1749\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   1750\u001b[0m     method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   1751\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mengine_kwargs,\n\u001b[1;32m   1752\u001b[0m )\n\u001b[1;32m   1754\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_case_sensitive(name\u001b[39m=\u001b[39mname, schema\u001b[39m=\u001b[39mschema)\n\u001b[1;32m   1755\u001b[0m \u001b[39mreturn\u001b[39;00m total_inserted\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:1335\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[0;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minf cannot be used with MySQL\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1334\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1335\u001b[0m     \u001b[39mraise\u001b[39;00m err\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:1325\u001b[0m, in \u001b[0;36mSQLAlchemyEngine.insert_records\u001b[0;34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msqlalchemy\u001b[39;00m \u001b[39mimport\u001b[39;00m exc\n\u001b[1;32m   1324\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m     \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39;49minsert(chunksize\u001b[39m=\u001b[39;49mchunksize, method\u001b[39m=\u001b[39;49mmethod)\n\u001b[1;32m   1326\u001b[0m \u001b[39mexcept\u001b[39;00m exc\u001b[39m.\u001b[39mSQLAlchemyError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1327\u001b[0m     \u001b[39m# GH34431\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[39m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m(1054, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown column \u001b[39m\u001b[39m'\u001b[39m\u001b[39minf(e0)?\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfield list\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m))(?#\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39m    )|inf can not be used with MySQL\u001b[39m\u001b[39m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:951\u001b[0m, in \u001b[0;36mSQLTable.insert\u001b[0;34m(self, chunksize, method)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    950\u001b[0m chunk_iter \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(arr[start_i:end_i] \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m data_list))\n\u001b[0;32m--> 951\u001b[0m num_inserted \u001b[39m=\u001b[39m exec_insert(conn, keys, chunk_iter)\n\u001b[1;32m    952\u001b[0m \u001b[39m# GH 46891\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[39mif\u001b[39;00m is_integer(num_inserted):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/sql.py:858\u001b[0m, in \u001b[0;36mSQLTable._execute_insert\u001b[0;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \u001b[39mExecute SQL statement inserting data\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[39m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    857\u001b[0m data \u001b[39m=\u001b[39m [\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(keys, row)) \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m data_iter]\n\u001b[0;32m--> 858\u001b[0m result \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mexecute(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtable\u001b[39m.\u001b[39;49minsert(), data)\n\u001b[1;32m    859\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mrowcount\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1295\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     util\u001b[39m.\u001b[39mraise_(\n\u001b[1;32m   1292\u001b[0m         exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement), replace_context\u001b[39m=\u001b[39merr\n\u001b[1;32m   1293\u001b[0m     )\n\u001b[1;32m   1294\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\u001b[39mself\u001b[39;49m, multiparams, params, _EMPTY_EXECUTION_OPTS)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/sql/elements.py:325\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_execute_on_connection\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m, connection, multiparams, params, execution_options, _force\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    323\u001b[0m ):\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m _force \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupports_execution:\n\u001b[0;32m--> 325\u001b[0m         \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49m_execute_clauseelement(\n\u001b[1;32m    326\u001b[0m             \u001b[39mself\u001b[39;49m, multiparams, params, execution_options\n\u001b[1;32m    327\u001b[0m         )\n\u001b[1;32m    328\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    329\u001b[0m         \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1487\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[1;32m   1475\u001b[0m compiled_cache \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[1;32m   1476\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_compiled_cache\n\u001b[1;32m   1477\u001b[0m )\n\u001b[1;32m   1479\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1480\u001b[0m     dialect\u001b[39m=\u001b[39mdialect,\n\u001b[1;32m   1481\u001b[0m     compiled_cache\u001b[39m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1485\u001b[0m     linting\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mcompiler_linting \u001b[39m|\u001b[39m compiler\u001b[39m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1486\u001b[0m )\n\u001b[0;32m-> 1487\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[1;32m   1488\u001b[0m     dialect,\n\u001b[1;32m   1489\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_compiled,\n\u001b[1;32m   1490\u001b[0m     compiled_sql,\n\u001b[1;32m   1491\u001b[0m     distilled_params,\n\u001b[1;32m   1492\u001b[0m     execution_options,\n\u001b[1;32m   1493\u001b[0m     compiled_sql,\n\u001b[1;32m   1494\u001b[0m     distilled_params,\n\u001b[1;32m   1495\u001b[0m     elem,\n\u001b[1;32m   1496\u001b[0m     extracted_params,\n\u001b[1;32m   1497\u001b[0m     cache_hit\u001b[39m=\u001b[39;49mcache_hit,\n\u001b[1;32m   1498\u001b[0m )\n\u001b[1;32m   1499\u001b[0m \u001b[39mif\u001b[39;00m has_events:\n\u001b[1;32m   1500\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_execute(\n\u001b[1;32m   1501\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1502\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1506\u001b[0m         ret,\n\u001b[1;32m   1507\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1851\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1848\u001b[0m             branched\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   1850\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1851\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[1;32m   1852\u001b[0m         e, statement, parameters, cursor, context\n\u001b[1;32m   1853\u001b[0m     )\n\u001b[1;32m   1855\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2032\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2030\u001b[0m     util\u001b[39m.\u001b[39mraise_(newraise, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me)\n\u001b[1;32m   2031\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[0;32m-> 2032\u001b[0m     util\u001b[39m.\u001b[39;49mraise_(\n\u001b[1;32m   2033\u001b[0m         sqlalchemy_exception, with_traceback\u001b[39m=\u001b[39;49mexc_info[\u001b[39m2\u001b[39;49m], from_\u001b[39m=\u001b[39;49me\n\u001b[1;32m   2034\u001b[0m     )\n\u001b[1;32m   2035\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2036\u001b[0m     util\u001b[39m.\u001b[39mraise_(exc_info[\u001b[39m1\u001b[39m], with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/compat.py:207\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    204\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[1;32m    206\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[1;32m    208\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1788\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1786\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1788\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_executemany(\n\u001b[1;32m   1789\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1790\u001b[0m         )\n\u001b[1;32m   1791\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m parameters \u001b[39mand\u001b[39;00m context\u001b[39m.\u001b[39mno_parameters:\n\u001b[1;32m   1792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/default.py:729\u001b[0m, in \u001b[0;36mDefaultDialect.do_executemany\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_executemany\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 729\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecutemany(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) table taxi_trips has no column named distance\n[SQL: INSERT INTO taxi_trips (id, pickup_datetime, dropoff_datetime, passenger_count, distance, \"PULocationID\", \"DOLocationID\", fare_amount, total_amount, pickup_hour, pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, \"Distance\", vendor_name, \"Trip_Pickup_DateTime\", \"Trip_Dropoff_DateTime\", \"Passenger_Count\", \"Trip_Distance\", \"Start_Lon\", \"Start_Lat\", \"Rate_Code\", store_and_forward, \"End_Lon\", \"End_Lat\", \"Payment_Type\", \"Fare_Amt\", surcharge, mta_tax, \"Tip_Amt\", \"Tolls_Amt\", \"Total_Amt\") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)]\n[parameters: ((10566313, '2015-01-26 00:57:34.000000', '2015-01-26 01:06:47.000000', 1.0, 3.862425613907204, 164.0, 79.0, 10.0, 12.8, 0.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), (7100166, '2015-01-17 21:43:25.000000', '2015-01-17 21:47:11.000000', 1.0, 1.287475204635735, 234.0, 90.0, 4.5, 7.25, 21.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), (332144, '2015-01-01 20:37:28.000000', '2015-01-01 20:48:13.000000', 3.0, 2.156520967764856, 142.0, 161.0, 8.5, 9.8, 20.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), (841470, '2015-01-03 10:43:15.000000', '2015-01-03 10:50:28.000000', 1.0, 4.538350096340965, 229.0, 148.0, 9.5, 11.9, 10.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), (6119963, '2015-01-15 20:31:59.000000', '2015-01-15 20:36:17.000000', 1.0, 1.3035686446936816, 249.0, 114.0, 5.0, 7.68, 20.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), (8807639, '2015-01-22 06:50:02.000000', '2015-01-22 06:55:14.000000', 1.0, 1.931212806953602, 239.0, 142.0, 6.5, 7.3, 6.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), (3193240, '2015-01-09 09:03:50.000000', '2015-01-09 09:20:19.000000', 1.0, 2.7358848098509365, 24.0, 143.0, 11.5, 12.3, 9.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None), (12323399, '2015-01-31 07:50:47.000000', '2015-01-31 07:54:26.000000', 1.0, 0.7724851227814409, 164.0, 170.0, 4.5, 6.3, 7.0, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None)  ... displaying 10 of 1793755 total bound parameter sets ...  (10714323, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'VTS', '2009-12-20 08:09:00', '2009-12-20 08:17:00', 1.0, 1.4, -73.985347, 40.758908, None, None, -73.97394, 40.764715, 'Credit', 6.5, 0.0, 0.5, 3.0, 0.0, 10.0), (5535768, None, None, None, None, None, None, None, None, None, None, None, None, None, None, 'VTS', '2009-12-14 09:18:00', '2009-12-14 09:39:00', 2.0, 7.36, -73.962407, 40.767188, None, None, -74.01495, 40.711175, 'Credit', 20.1, 0.0, 0.5, 3.5, 0.0, 24.1))]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b6ce43a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse error near line 2: near \"CREATE\": syntax error\n",
      "  FLOAT,     hours INTEGER,     newDATE DATE     )  CREATE TABLE IF NOT EXISTS d\n",
      "                                      error here ---^\n"
     ]
    }
   ],
   "source": [
    "!sqlite3 project.db < schema.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "976486aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>DATE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>days</th>\n",
       "      <th>newDATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>3</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>4</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>5</td>\n",
       "      <td>2009-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>2362</td>\n",
       "      <td>2015-06-26</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>26</td>\n",
       "      <td>2015-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "      <td>2363</td>\n",
       "      <td>2015-06-27</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>27</td>\n",
       "      <td>2015-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>2364</td>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>28</td>\n",
       "      <td>2015-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>2365</td>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>29</td>\n",
       "      <td>2015-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>2366</td>\n",
       "      <td>2015-06-30</td>\n",
       "      <td>40.77898</td>\n",
       "      <td>-73.96925</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>30</td>\n",
       "      <td>2015-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2367 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       DATE  LATITUDE  LONGITUDE                         NAME  days  \\\n",
       "0        0 2009-01-01  40.77898  -73.96925  NY CITY CENTRAL PARK, NY US     1   \n",
       "1        1 2009-01-02  40.77898  -73.96925  NY CITY CENTRAL PARK, NY US     2   \n",
       "2        2 2009-01-03  40.77898  -73.96925  NY CITY CENTRAL PARK, NY US     3   \n",
       "3        3 2009-01-04  40.77898  -73.96925  NY CITY CENTRAL PARK, NY US     4   \n",
       "4        4 2009-01-05  40.77898  -73.96925  NY CITY CENTRAL PARK, NY US     5   \n",
       "...    ...        ...       ...        ...                          ...   ...   \n",
       "2362  2362 2015-06-26  40.77898  -73.96925  NY CITY CENTRAL PARK, NY US    26   \n",
       "2363  2363 2015-06-27  40.77898  -73.96925  NY CITY CENTRAL PARK, NY US    27   \n",
       "2364  2364 2015-06-28  40.77898  -73.96925  NY CITY CENTRAL PARK, NY US    28   \n",
       "2365  2365 2015-06-29  40.77898  -73.96925  NY CITY CENTRAL PARK, NY US    29   \n",
       "2366  2366 2015-06-30  40.77898  -73.96925  NY CITY CENTRAL PARK, NY US    30   \n",
       "\n",
       "      newDATE  \n",
       "0     2009-01  \n",
       "1     2009-01  \n",
       "2     2009-01  \n",
       "3     2009-01  \n",
       "4     2009-01  \n",
       "...       ...  \n",
       "2362  2015-06  \n",
       "2363  2015-06  \n",
       "2364  2015-06  \n",
       "2365  2015-06  \n",
       "2366  2015-06  \n",
       "\n",
       "[2367 rows x 7 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_table(\"daily_weather\", con=DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d98db556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>Distance</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, fare_amount, pickup_datetime, pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude, passenger_count, Distance, day_of_week]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_table(\"uber_trips\", con=DATABASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287644ea",
   "metadata": {},
   "source": [
    "In this section, six queries are done to the SQL tables in order to determine the following information about taxi and uber trips:\n",
    "* For 01-2009 through 06-2015, what hour of the day was the most popular to take a yellow taxi? The result should have 24 bins.\n",
    "* For the same time frame, what day of the week was the most popular to take an uber? The result should have 7 bins.\n",
    "* What is the 95% percentile of distance traveled for all hired trips during July 2013?\n",
    "* What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?\n",
    "* Which 10 days in 2014 were the windiest, and how many hired trips were made on those days?\n",
    "* During Hurricane Sandy in NYC (Oct 29-30, 2012) and the week leading up to it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e54b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each query, be sure to execute it in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4753fcd",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [x] For 01-2009 through 06-2015, what hour of the day was the most popular to take a yellow taxi? The result should have 24 bins.\n",
    "* [x] For the same time frame, what day of the week was the most popular to take an uber? The result should have 7 bins.\n",
    "* [ ] What is the 95% percentile of distance traveled for all hired trips during July 2013?\n",
    "* [ ] What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?\n",
    "* [ ] Which 10 days in 2014 were the windiest, and how many hired trips were made on those days?\n",
    "* [ ] During Hurricane Sandy in NYC (Oct 29-30, 2012) and the week leading up to it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371b8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tips\n",
    "# You may wish to use SQLAlchemy within the notebook to help craft these queries and query files. \n",
    "# You can also use pandas to help check the validity of your queries.\n",
    "# You may want to familiarize yourself with the WITH <name> AS and WITH RECURSIVE <name> AS expressions in SQL. \n",
    "# This is a good resource with a lot of examples to help get familiar.\n",
    "# There are quite a few examples using UNION ALL - this will help \"flatten\" tables that have common columns \n",
    "# (e.g. fare amount, pickup dates, etc) into a singular shared column (for example, taxi fares and uber fares are in one column).\n",
    "# Look at the example query that starts with WITH RECURSIVE dates(x) AS for help with the 6th query.\n",
    "# You may also want to familiarize yourself with the COALESCE expression in SQL. This is a decent tutorial to look through.\n",
    "# This Stack Overflow post will be helpful when crafting queries for figuring out percentiles/quantiles.\n",
    "# This Stack Overflow post will be helpful for grouping results by timeframe, e.g. by hour, day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_to_file(query, outfile):\n",
    "    connection = sqlite3.connect(outfile)\n",
    "    with connection:\n",
    "        result = connection.execute(query)\n",
    "    for row in result:\n",
    "        print(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c576ef10",
   "metadata": {},
   "source": [
    "### For the same time frame, what day of the week was the most popular to take an uber? \n",
    "In this portion, in order to determine the most popular day of the week for uber trips, the number of times a certain day of week appears in the dataset is counted and then ordered by days of that count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e142954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def uber_popular_day_of_week(df = uber_data):\n",
    "     \n",
    "#      day_of_week_group = df.groupby('day_of_week').size().sort_values(ascending=False)\n",
    "#      return day_of_week_group\n",
    "\n",
    "# uber_popular_day_of_week()\n",
    "Uber_day_most_pop = \"\"\"\n",
    "    SELECT day_of_week from uber_trips ORDER BY COUNT(day_of_week)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51fb9fe6",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) misuse of aggregate: COUNT()\n[SQL: \n    SELECT day_of_week from uber_trips ORDER BY COUNT(day_of_week)\n]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1808\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1808\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1809\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1810\u001b[0m         )\n\u001b[1;32m   1812\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 732\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: misuse of aggregate: COUNT()",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project Scaffolding.ipynb Cell 55\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y110sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m engine\u001b[39m.\u001b[39;49mexecute(Uber_day_most_pop)\u001b[39m.\u001b[39mfetchall()\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/deprecations.py:401\u001b[0m, in \u001b[0;36m_decorate_with_warning.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_warning:\n\u001b[1;32m    400\u001b[0m     _warn_with_version(message, version, wtype, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m--> 401\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:3152\u001b[0m, in \u001b[0;36mEngine.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   3134\u001b[0m \u001b[39m\"\"\"Executes the given construct and returns a\u001b[39;00m\n\u001b[1;32m   3135\u001b[0m \u001b[39m:class:`_engine.CursorResult`.\u001b[39;00m\n\u001b[1;32m   3136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3149\u001b[0m \n\u001b[1;32m   3150\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3151\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnect(close_with_result\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 3152\u001b[0m \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49mexecute(statement, \u001b[39m*\u001b[39;49mmultiparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1280\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(statement, util\u001b[39m.\u001b[39mstring_types):\n\u001b[1;32m   1272\u001b[0m     util\u001b[39m.\u001b[39mwarn_deprecated_20(\n\u001b[1;32m   1273\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing a string to Connection.execute() is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1274\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeprecated and will be removed in version 2.0.  Use the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdriver-level SQL string.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1278\u001b[0m     )\n\u001b[0;32m-> 1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_driver_sql(\n\u001b[1;32m   1281\u001b[0m         statement,\n\u001b[1;32m   1282\u001b[0m         multiparams,\n\u001b[1;32m   1283\u001b[0m         params,\n\u001b[1;32m   1284\u001b[0m         _EMPTY_EXECUTION_OPTS,\n\u001b[1;32m   1285\u001b[0m         future\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1286\u001b[0m     )\n\u001b[1;32m   1288\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1289\u001b[0m     meth \u001b[39m=\u001b[39m statement\u001b[39m.\u001b[39m_execute_on_connection\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1584\u001b[0m, in \u001b[0;36mConnection._exec_driver_sql\u001b[0;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[1;32m   1574\u001b[0m         (\n\u001b[1;32m   1575\u001b[0m             statement,\n\u001b[1;32m   1576\u001b[0m             distilled_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1580\u001b[0m             statement, distilled_parameters, execution_options\n\u001b[1;32m   1581\u001b[0m         )\n\u001b[1;32m   1583\u001b[0m dialect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\n\u001b[0;32m-> 1584\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[1;32m   1585\u001b[0m     dialect,\n\u001b[1;32m   1586\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_statement,\n\u001b[1;32m   1587\u001b[0m     statement,\n\u001b[1;32m   1588\u001b[0m     distilled_parameters,\n\u001b[1;32m   1589\u001b[0m     execution_options,\n\u001b[1;32m   1590\u001b[0m     statement,\n\u001b[1;32m   1591\u001b[0m     distilled_parameters,\n\u001b[1;32m   1592\u001b[0m )\n\u001b[1;32m   1594\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m future:\n\u001b[1;32m   1595\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1851\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1848\u001b[0m             branched\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   1850\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1851\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[1;32m   1852\u001b[0m         e, statement, parameters, cursor, context\n\u001b[1;32m   1853\u001b[0m     )\n\u001b[1;32m   1855\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2032\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2030\u001b[0m     util\u001b[39m.\u001b[39mraise_(newraise, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me)\n\u001b[1;32m   2031\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[0;32m-> 2032\u001b[0m     util\u001b[39m.\u001b[39;49mraise_(\n\u001b[1;32m   2033\u001b[0m         sqlalchemy_exception, with_traceback\u001b[39m=\u001b[39;49mexc_info[\u001b[39m2\u001b[39;49m], from_\u001b[39m=\u001b[39;49me\n\u001b[1;32m   2034\u001b[0m     )\n\u001b[1;32m   2035\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2036\u001b[0m     util\u001b[39m.\u001b[39mraise_(exc_info[\u001b[39m1\u001b[39m], with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/compat.py:207\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    204\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[1;32m    206\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[1;32m    208\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1808\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1806\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1808\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1809\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1810\u001b[0m         )\n\u001b[1;32m   1812\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[1;32m   1813\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1814\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1815\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1819\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[1;32m   1820\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 732\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) misuse of aggregate: COUNT()\n[SQL: \n    SELECT day_of_week from uber_trips ORDER BY COUNT(day_of_week)\n]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "engine.execute(Uber_day_most_pop).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08633f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "result = engine.execute(Uber_day_most_pop).fetchall()\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2436db02",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: uber_trips",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project Scaffolding.ipynb Cell 57\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y111sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m write_query_to_file(Uber_day_most_pop, \u001b[39m\"\u001b[39;49m\u001b[39mUber_most_pop_day.sql\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project Scaffolding.ipynb Cell 57\u001b[0m in \u001b[0;36mwrite_query_to_file\u001b[0;34m(query, outfile)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y111sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m connection \u001b[39m=\u001b[39m sqlite3\u001b[39m.\u001b[39mconnect(outfile)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y111sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m connection:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y111sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     result \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mexecute(query)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y111sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m result:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y111sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(row)\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: uber_trips"
     ]
    }
   ],
   "source": [
    "write_query_to_file(Uber_day_most_pop, \"Uber_most_pop_day.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b5b91",
   "metadata": {},
   "source": [
    "### Most Popular Hour Taxis Query\n",
    "\n",
    "_**TODO:**  In this section, in order to determine the post popular hour for a taxi pickup to occur at, the number of times a pickup hour occurs in the database is counted, then it is ordered by that count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "228ef488",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_hour_most_pop = \"\"\"\n",
    "    SELECT pickup_hour FROM taxi_trips ORDER BY COUNT(pickup_hour)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6652192d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such column: pickup_hour\n[SQL: \n    SELECT pickup_hour FROM taxi_trips ORDER BY COUNT(pickup_hour)\n    ]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1808\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1808\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1809\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1810\u001b[0m         )\n\u001b[1;32m   1812\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 732\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such column: pickup_hour",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project Scaffolding.ipynb Cell 61\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m engine\u001b[39m.\u001b[39;49mexecute(taxi_hour_most_pop)\u001b[39m.\u001b[39mfetchall()\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/deprecations.py:401\u001b[0m, in \u001b[0;36m_decorate_with_warning.<locals>.warned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m skip_warning:\n\u001b[1;32m    400\u001b[0m     _warn_with_version(message, version, wtype, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m--> 401\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:3152\u001b[0m, in \u001b[0;36mEngine.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   3134\u001b[0m \u001b[39m\"\"\"Executes the given construct and returns a\u001b[39;00m\n\u001b[1;32m   3135\u001b[0m \u001b[39m:class:`_engine.CursorResult`.\u001b[39;00m\n\u001b[1;32m   3136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3149\u001b[0m \n\u001b[1;32m   3150\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3151\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnect(close_with_result\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 3152\u001b[0m \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49mexecute(statement, \u001b[39m*\u001b[39;49mmultiparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1280\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(statement, util\u001b[39m.\u001b[39mstring_types):\n\u001b[1;32m   1272\u001b[0m     util\u001b[39m.\u001b[39mwarn_deprecated_20(\n\u001b[1;32m   1273\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing a string to Connection.execute() is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1274\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeprecated and will be removed in version 2.0.  Use the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdriver-level SQL string.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1278\u001b[0m     )\n\u001b[0;32m-> 1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_driver_sql(\n\u001b[1;32m   1281\u001b[0m         statement,\n\u001b[1;32m   1282\u001b[0m         multiparams,\n\u001b[1;32m   1283\u001b[0m         params,\n\u001b[1;32m   1284\u001b[0m         _EMPTY_EXECUTION_OPTS,\n\u001b[1;32m   1285\u001b[0m         future\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1286\u001b[0m     )\n\u001b[1;32m   1288\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1289\u001b[0m     meth \u001b[39m=\u001b[39m statement\u001b[39m.\u001b[39m_execute_on_connection\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1584\u001b[0m, in \u001b[0;36mConnection._exec_driver_sql\u001b[0;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[1;32m   1574\u001b[0m         (\n\u001b[1;32m   1575\u001b[0m             statement,\n\u001b[1;32m   1576\u001b[0m             distilled_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1580\u001b[0m             statement, distilled_parameters, execution_options\n\u001b[1;32m   1581\u001b[0m         )\n\u001b[1;32m   1583\u001b[0m dialect \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\n\u001b[0;32m-> 1584\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[1;32m   1585\u001b[0m     dialect,\n\u001b[1;32m   1586\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_statement,\n\u001b[1;32m   1587\u001b[0m     statement,\n\u001b[1;32m   1588\u001b[0m     distilled_parameters,\n\u001b[1;32m   1589\u001b[0m     execution_options,\n\u001b[1;32m   1590\u001b[0m     statement,\n\u001b[1;32m   1591\u001b[0m     distilled_parameters,\n\u001b[1;32m   1592\u001b[0m )\n\u001b[1;32m   1594\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m future:\n\u001b[1;32m   1595\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1851\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1848\u001b[0m             branched\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   1850\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1851\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[1;32m   1852\u001b[0m         e, statement, parameters, cursor, context\n\u001b[1;32m   1853\u001b[0m     )\n\u001b[1;32m   1855\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:2032\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2030\u001b[0m     util\u001b[39m.\u001b[39mraise_(newraise, with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m], from_\u001b[39m=\u001b[39me)\n\u001b[1;32m   2031\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[0;32m-> 2032\u001b[0m     util\u001b[39m.\u001b[39;49mraise_(\n\u001b[1;32m   2033\u001b[0m         sqlalchemy_exception, with_traceback\u001b[39m=\u001b[39;49mexc_info[\u001b[39m2\u001b[39;49m], from_\u001b[39m=\u001b[39;49me\n\u001b[1;32m   2034\u001b[0m     )\n\u001b[1;32m   2035\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2036\u001b[0m     util\u001b[39m.\u001b[39mraise_(exc_info[\u001b[39m1\u001b[39m], with_traceback\u001b[39m=\u001b[39mexc_info[\u001b[39m2\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/compat.py:207\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    204\u001b[0m     exception\u001b[39m.\u001b[39m__cause__ \u001b[39m=\u001b[39m replace_context\n\u001b[1;32m    206\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mraise\u001b[39;00m exception\n\u001b[1;32m    208\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39m# credit to\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[39m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[39m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[39mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py:1808\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1806\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1808\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1809\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1810\u001b[0m         )\n\u001b[1;32m   1812\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[1;32m   1813\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1814\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1815\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1819\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[1;32m   1820\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 732\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such column: pickup_hour\n[SQL: \n    SELECT pickup_hour FROM taxi_trips ORDER BY COUNT(pickup_hour)\n    ]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "engine.execute(taxi_hour_most_pop).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670ba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(taxi_hour_most_pop, \"Taxi_hour_most_pop.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe4210",
   "metadata": {},
   "source": [
    "### What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_days_2009 = \"\"\"\n",
    "SELECT pickup_datetime, AVG(distance) \n",
    "ORDER BY COUNT(pickup_datetime) LIMIT 10\n",
    "WHERE YEAR(pickup_datetime) = 2009\n",
    "FROM taxi_trips\n",
    "JOIN uber_trips ON taxi_data.pickup_datetime = uber_trips.pickup_datetime \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0047991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(top_10_days_2009).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec07b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(top_10_days_2009, \"top_10_days_2009.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d2ff1d",
   "metadata": {},
   "source": [
    "### Which 10 days in 2014 were the windiest, and how many hired trips were made on those days?\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather data below\n",
    "# 5. Which 10 days in 2014 were the windiest on average, and how many hired trips were made on those days?\n",
    "\n",
    "windiest_days= \"\"\"\n",
    "From daily_wheather WHERE Year(Date) LIKE 2014 ORDER BY wind LIMIT 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba588b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(windiest_days).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810602a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(windiest_days, \"windiest_days.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233493b9",
   "metadata": {},
   "source": [
    "### What is the 95% percentile of distance traveled for all hired trips during July 2013?\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c8f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_95th_2013 =\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe0542",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(distance_95th_2013).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875e09b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(distance_95th_2013, \"95th_distance_2013.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0963a0f",
   "metadata": {},
   "source": [
    "### During Hurricane Sandy in NYC (Oct 29-30, 2012) and the week leading up to it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed?\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607aece2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 6. During Hurricane Sandy in NYC (Oct 29-30, 2012), plus the week leading up and the week after, how many trips were taken each hour, \n",
    "# and for each hour, how much precipitation did NYC receive and what was the sustained wind speed? \n",
    "# There should be an entry for every single hour, even if no rides were taken, no precipitation was measured, or there was no wind.\n",
    "\n",
    "sandy = \"\"\" \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb918b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(sandy).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97d083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(sandy, \"Sandy.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Create an appropriate visualization for the first query/question in part 3\n",
    "* [ ] Create a visualization that shows the average distance traveled per month (regardless of year - so group by each month). Include the 90% confidence interval around the mean in the visualization\n",
    "* [ ] Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR (you can use bboxfinder to help). Create a visualization that compares what day of the week was most popular for drop offs for each airport.\n",
    "* [ ] Create a heatmap of all hired trips over a map of the area. Consider using KeplerGL or another library that helps generate geospatial visualizations.\n",
    "* [ ] Create a scatter plot that compares tip amount versus distance.\n",
    "* [ ] Create another scatter plot that compares tip amount versus precipitation amount.\n",
    "\n",
    "_Be sure these cells are executed so that the visualizations are rendered when the notebook is submitted._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51149848",
   "metadata": {},
   "source": [
    "### Visualization: For 01-2009 through 06-2015, what hour of the day was the most popular to take a yellow taxi? \n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016671a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_hour_of_day():\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Most Popular Hour of the Day to take a Yellow Taxi January 2009 to June 2015\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8fc27581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_taxi_hour():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    data = engine.execute(taxi_hour_most_pop).fetchall()\n",
    "    #pd.read_sql_table(\"daily_weather\", con=DATABASE_URL)\n",
    "    return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "77a1eda0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'taxi_hour_most_pop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project Scaffolding.ipynb Cell 83\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y144sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m taxi_hour_most_pop \u001b[39m=\u001b[39m get_data_for_visual_taxi_hour()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y144sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plot_visual_taxi_hour(taxi_hour_most_pop)\n",
      "\u001b[1;32m/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project Scaffolding.ipynb Cell 83\u001b[0m in \u001b[0;36mget_data_for_visual_taxi_hour\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y144sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_data_for_visual_taxi_hour\u001b[39m():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y144sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Query SQL database for the data needed.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y144sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# You can put the data queried into a pandas dataframe, if you wish\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y144sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     data \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39mexecute(taxi_hour_most_pop)\u001b[39m.\u001b[39mfetchall()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y144sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m#pd.read_sql_table(\"daily_weather\", con=DATABASE_URL)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/laurelhickey/Documents/GitHub/Tools_for_Analytics_Project/Project%20Scaffolding.ipynb#Y144sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[0;31mNameError\u001b[0m: name 'taxi_hour_most_pop' is not defined"
     ]
    }
   ],
   "source": [
    "taxi_hour_most_pop = get_data_for_visual_taxi_hour()\n",
    "plot_visual_taxi_hour(taxi_hour_most_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc9877d",
   "metadata": {},
   "source": [
    "### Visualization: Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR. Compares what day of the week was most popular for drop offs for each airport.\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "\n",
    "EWR (Newark): -74.195995,40.664103,-74.148445,40.713045\n",
    "\n",
    "JFK: -73.832496,40.618362,-73.744262,40.669421\n",
    "\n",
    "LGA (LaGuardia): -73.892010,40.764638,-73.852357,40.787711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2318a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to be fixed up for our purposes\n",
    "# Just looking at uber data?????\n",
    "def get_zone(lon,lat,airport_boxes):\n",
    "    \n",
    "    #MY CODE STARTS HERE\n",
    "    # long is x lat is y \n",
    "    \n",
    "    for item in airport_boxes:\n",
    "        #print(item)\n",
    "        if (item[1][0][0] <= lon <= item[1][1][0]) & (item[1][0][1] <= lat <= item[1][2][1]):\n",
    "            zone = item[0]\n",
    "            # want to return airport name \n",
    "        else:\n",
    "            # want to return na if no airport name\n",
    "            break\n",
    "\n",
    "df['dropoff_zone'] = df.apply(lambda x: get_zone(x[\"dropoff_longitude\"], x[\"dropoff_latitude\"], zone_table),axis =1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e92c3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_hour_of_day(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd695dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_n()\n",
    "plot_visual_n(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7595367c",
   "metadata": {},
   "source": [
    "### Visualization:  A heatmap of all hired trips over a map of the area\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf53e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_hour_of_day(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc57b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_n()\n",
    "plot_visual_n(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b19657f",
   "metadata": {},
   "source": [
    "### Visualization: The average distance traveled per month (regardless of year - so group by each month). Include the 90% confidence interval around the mean in the visualization\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each visualization._\n",
    "\n",
    "_The example below makes use of the `matplotlib` library. There are other libraries, including `pandas` built-in plotting library, kepler for geospatial data representation, `seaborn`, and others._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528da4c7",
   "metadata": {},
   "source": [
    "### Visualization: A scatter plot that compares tip amount versus distance\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3012e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_hour_of_day(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9055e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_n()\n",
    "plot_visual_n(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f240076",
   "metadata": {},
   "source": [
    "### Visualization: A scatter plot that compares tip amount versus precipitation amount\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c011ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visual_hour_of_day(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103741b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_n()\n",
    "plot_visual_n(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each visualization._\n",
    "\n",
    "_The example below makes use of the `matplotlib` library. There are other libraries, including `pandas` built-in plotting library, kepler for geospatial data representation, `seaborn`, and others._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_n(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_n():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_n()\n",
    "plot_visual_n(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6fa68bb73451efc61706d715b46efd745ccab7b86462809ef43c0a1824a5bb9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
